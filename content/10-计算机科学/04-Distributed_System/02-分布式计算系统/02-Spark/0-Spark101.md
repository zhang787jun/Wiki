---
title: "0-Spark 101"
layout: page
date: 2099-06-02 00:00
---
[TOC]


# 1. Hello, Spark

Apache Spark 是用于大规模资料处理的**计算引擎**

Apache Spark 是一个小巧玲珑的项目，美国加州大学伯克利分校（UC Berkeley）的AMP实验室于2009年开发。**使用的语言是Scala**，项目的core部分的代码只有63个Scala文件，充分体现了精简之美。


Spark具有如下几个主要特点：
1. 运行速度快：Spark使用先进的有向无环图（Directed Acyclic Graph,DAG）执行引擎，以支持循环数据流与内存计算，基于内存的执行速度可比HadoopMapReduce快上百倍，基于磁盘的执行速度也能快十倍；
2. 容易使用：Spark支持使用Scala、Java、Python和R语言进行编程，简洁的API设计有助于用户轻松构建并行程序，并且可以通过Spark Shell进行交互式编程；
3. 通用性：Spark提供了完整而强大的技

# 2. 优秀的参考资料
自己的OneNote笔记 

OneDriver
《图解Spark》
   
1. https://aiyanbo.gitbooks.io/spark-programming-guide-zh-cn/content/programming-guide/rdds/rdd-persistences.html
2. https://intellipaat.com/blog/tutorial/spark-tutorial/spark-architecture/
3. https://github.com/apache/spark


