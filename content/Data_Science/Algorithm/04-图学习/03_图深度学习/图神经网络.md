---
title: "01.图神经网络模型"
layout: page
date: 2019-06-17 00:00
---
[TOC]

# 1. GNN简介

图卷积神经网络(Graph Neural Networks)

图神经网络的概念第一次在[论文](https://persagen.com/files/misc/scarselli2009graph.pdf)中提出，该论文将现存的神经网络模型扩展到处理图领域的数据。在一个图结构中，**每一个节点由它自身的特征以及与其相连的节点特征来定义该节点**。

![](https://pic4.zhimg.com/v2-95f73c5719cb222cc86eb1342640655f_r.jpg)
依据**更新方式**分类

1. 图卷积网络(GCN)
2. 基于注意力更新的图网络(GAT)
3. 基于门控的更新的图网络
4. 具有跳边的图网络


论文对GNN模型分类如下：

1. 图卷积网络(Graph convolutional networks)和图注意力网络(graph attention networks)，因为涉及到传播步骤(propagation step)。
2. 图的空域网络(spatial-temporal networks)，因为该模型通常用在动态图(dynamic graph)上。
3. 图的自编码(auto-encoder)，因为该模型通常使用无监督学习(unsupervised)的方式。
4. 图生成网络(generative networks)，因为是生成式网络。



## 1.1. GCNs 图卷积网络s

图卷积网络(Graph convolutional networks) GCN的边权重：
1. 与节点的度相关
2. 不可学习
### 1.1.1. 基于谱的GCN
传播(propagation)指的是汇集从邻居节点和连接的边的信息

#### GraphSage
原始的GCN方法每个节点的表示依赖于图中所有的其他节点，计算复杂度过大，且由于依赖于拉普拉斯矩阵训练的网络不惧泛化性。

GraphSAGE对于每个节点的计算不涉及整张图，所以效率更加高，不过为了缓解深度加深感受野指数爆炸的现象，GraphSAGE每次信息计算通过采样只使用部分邻居。

FastGCN对GraphSAGE的随机采样加以改进，针对每个节点连接其他节点个数的不同给定不同的重要性。

[公式]



还有一些限制感受野的其他方法，咱也不懂.



采样函数实现

GraphSage的作者提出了采样算法来使得模型能够以Mini-batch的方式进行训练，算法伪代码见论文附录A。

假设我们要利用中心节点的k阶邻居信息，则在聚合的时候，需要从第k阶邻居传递信息到k-1阶邻居，并依次传递到中心节点。
采样的过程刚好与此相反，在构造第t轮训练的Mini-batch时，我们从中心节点出发，在前序节点集合中采样NtN_tNt​个邻居节点加入采样集合。
接着将邻居节点作为新的中心节点继续进行第t-1轮训练的节点采样，以此类推。
最后将采样到的节点和边一起构造得到子图。

### 1.1.2. 非基于谱的方法

####


## 1.2. GAT 图注意力网络

图注意力网络(Graph Attention Network)

### 1.2.1. Message Passing 消息传递机制


### 1.2.2. Gate 门机制机制

门机制(Gate)：目前在信息传播步骤中使用的门机制类似于GRU和LSTM模型，这种机制可以减小原始GNN模型的约束，并提升在图结构中的长期的信息传播

3.GAT 总结

GAT 的时间复杂度为 O(|V|FF'+|E|F')，其中 |V|FF' 是计算所有节点特征向量变换的时间复杂度 (即 Wh)，|E|F' 是计算 Attention 的时间复杂度。GAT 不依赖于完整的图结构，只依赖于边，因此可以用于 inductive 任务。GAT 可用于有向图。采用 Attention 机制，可以为不同的邻居节点分配不同的权重。4.参考文献


SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS




相比于传统的网络，GNN的深度一般更浅，原因是GNN的感受野随着深度的增加指数增大在信息传递过程中会引入大量噪声。所以在GNN中也有人尝试加入skip connection来缓解这个问题。下面是一个用Highway的方法的例子：

[公式]

当前的输出还有一部分来自于上层的输出。


为了方便读者更好地理解图神经网络的原理，我们花费了较长篇幅介绍图神经网络的思想和发展。总的来说，它由图信号理论和谱域图卷积发展而来，目前更多聚焦在空间域上的卷积方式，即将邻居节点的特征聚合给中心节点的方式来更新节点特征。



GCN、GraphSAGE和GAT是三种具有代表性的图神经网络。GCN仅适用于转导学习和无向图，即在未来有新节点加入时需要重新训练模型才能进行预测；GraphSAGE和GAT分别通过聚合器和注意力机制的方式将其扩展到归纳式学习，可用于新节点的预测，这对动态的股票市场来说是富有意义的。