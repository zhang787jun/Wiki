---
title: "大规模机器学习--分布式tensorflow"
date: 2019-06-12 00:00
render: True 
tag: Tensorflow,框架,AI,
---
[TOC]
# 大规模计算--分布式tensorflow

## 大规模大在何处

1. 训练输入量大
2. 训练模型大，参数存储量大
3. 计算量大


针对不同应用场景，提出不同解决方案
1. 训练输入量大
>  fe

2. 训练模型大，参数存储量大
>ff 
3. 计算量大
> 计算资源优化配置 
> 

## 单机--多CPU/GPU

同步更新与异步更新有图内模式（in-graph pattern）和图间模式（between-graph pattern）两 种模式，是独立于图内（in-graph）和图间（between-graph）的概念，也就是说无论是图本还是 图间都可以实现同步更新和异步更新，只是实现代码上会有些差异。

图内复制（in-graph replication）是指所有操作（operation）都在同一个图中，用一个客户 端来生成图，然后把所有操作分配到集群的所有参数服务器和工作节点上。图内复制和单机多 卡有点类似，是扩展到了多机多卡，但是数据分发还是在客户端一个节点上。这种方式的优势 是计算节点只需要调用 join()函数等待任务，客户端随时提交数据就可以训练。但劣势是训练数 据的分发在一个节点上，要分发给不同的工作节点，严重影响并发训练速度。因此，在数据量 很大的情况下，不推荐使用这种模式。

图间复制（between-graph replication）与图本复制对应，是指每一个工作节点创建一个图， 训练的参数保存在参数服务器，数据不用分发，各个工作节点独立计算，计算完成后，把要更 新的参数告诉参数服务器，参数服务器来更新参数。这种模式的优势是不需要数据分发，各个 工作节点都会创建图和读取数据进行训练。劣势是工作节点既是图的创建者又是计算任务的执 行者，如果某个工作节点宕机会影响集群的工作。这种模式是在数据量在 TB 级的时候，并发 性能很高。因此，大数据相关的深度学习还是推荐使用图间模式。在 14.6 节的对 MNIST 进行 分布式训练的例子中，我们就采用了这种方式。
