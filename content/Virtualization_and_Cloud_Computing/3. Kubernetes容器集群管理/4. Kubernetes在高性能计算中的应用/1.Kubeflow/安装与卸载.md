---
title: "Kubeflow--安装与卸载"
layout: page
date: 2099-06-02 00:00
---

[TOC]


# 1. 安装

**在现有kebernetes群集上的部署概述**

## 1.1. 最低系统要求
Kubernetes集群必须满足以下最低要求：
您的集群必须至少包含**1个工作节点**(Work node)，且最少为：
1. **4个CPU**
2. **50 GB的存储空间**
3. **12 GB内存**

## 1.2. 实践1.0版本

使用kfctl安装kubeflow


### 1.2.1. 安装kfctl
`kfctl` is the executable binary file that you use to deploy Kubeflow.
`kfctl` 是用于部署Kubeflow的可执行文件，通过ctl实现.
```shell
# 1. 安装kfctl
wget http://kubeflow.oss-cn-beijing.aliyuncs.com/kfctl_v1.0-0-g94c35cf_linux.tar.gz
tar zxvf kfctl_v1.0-0-g94c35cf_linux.tar.gz
sudo mv kfctl /usr/bin/

# 验证
kfctl version
```

### 1.2.2. 获得配置文件 

`kfctl_k8s_istio.yaml` 是Kubeflow官方的的配置文件（社区版），此配置使用其所有核心组件创建了Kubeflow的原始部署，而没有任何外部依赖性。可以根据您的环境需求自定义部署。

```shell
# 2. 通过kfctl生成应用的配置文件
export KF_NAME=my-kubeflow-2
export BASE_DIR=/home
export KF_DIR=${BASE_DIR}/${KF_NAME}
export CONFIG_URI="http://kubeflow.oss-cn-beijing.aliyuncs.com/kfctl_k8s_istio.v1.0.1.yaml"
sudo mkdir -p ${KF_DIR}
sudo chmod -R 777 ${KF_DIR}
cd ${KF_DIR}

```


### 1.2.3. 配置存储

KubeFlow里面有4个有状态应用（Deployment），通过PVC 声明了存储情况：
1. mino
2. mysql
3. katib-mysql
4. metadata-db



4个Deployment，指定了4个PVC，每个PVC都要去k8s系统中寻找并申请符合要求的PV资源。
所以，需要先创建4个符合要求的PV资源


app(Deployment)|PVC|PC（实际不对应*）
--|--|--|
minio|minio-pv-claim|minio-pv
mysql|mysql-pv-claim|mysql-pv
katib-mysql|katib-mysql|katib-mysql-pv
metadata-db|metadata-mysql|metadata-mysql


PVC最终绑定哪个PV 其实是看PVC声明文件里面怎么说，默认条件下是由PVC文件寻找符合要求的PV，所以PV名字可能与上表不一致。

```shell
cat << EOF > local_pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: mysql-pv
  namespace: kubeflow
  labels:
    type: local
    app: mysql-pv
    key: kubeflow-pv
spec:
  capacity:
    storage: 25Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /data/mysql-pv
    type: DirectoryOrCreate
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: minio-pv
  namespace: kubeflow
  labels:
    type: local
    app: minio-pv
    key: kubeflow-pv
spec:
  capacity:
    storage: 25Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /data/minio-pv
    type: DirectoryOrCreate
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: katib-mysql-pv
  namespace: kubeflow
  labels:
    type: local
    app: katib-mysql-pv
spec:
  capacity:
    storage: 25Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /data/katib-mysql-pv
    type: DirectoryOrCreate
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: metadata-mysql-pv
  namespace: kubeflow
  labels:
    type: local
    app: metadata-mysql-pv
    key: kubeflow-pv
spec:
  capacity:
    storage: 25Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /data/metadata-mysql-pv
    type: DirectoryOrCreate
EOF
kubectl create -f local_pv.yaml
```
### 1.2.4. 安装 

```shell
kfctl apply -V -f ${CONFIG_URI}
export CONFIG=${KF_DIR}/kfctl_k8s_istio.v1.0.1.yaml

# 中间cert会错误，各个pod之间有依赖，需要等待一会
# 命令完成后，部署依然没有完成，而是转为后台部署
```


# 2. 查看与验证

## 2.1. Shell
```shell
kubectl get pods -n kubeflow 

kubectl get pods -n cert-manager

kubectl get pods -n knative-serving

kubectl get pods -n istio-system

kubectl get pvc -n kubeflow 

kubectl get services -n kubeflow

kubectl get services -n knative-serving

kubectl get services -n istio-system


kubectl proxy & kubectl get namespace $NAMESPACE -o json |jq '.spec = {"finalizers":[]}' >temp.json
curl -k -H "Content-Type: application/json" -X PUT --data-binary @temp.json 127.0.0.1:8001/api/v1/namespaces/$NAMESPACE/finalize
```


## 2.2. Kubeflow UI
kubeflow中，附带了许多Web UI:
1. Argo UI
2. Central UI for navigation
3. JupyterHub
4. Katib
5. TFJobs Dashboard



# 3. 卸载

```shell
# If you want to delete all the resources, including storage:
kfctl delete -f ${CONFIG_FILE} --delete_storage

# If you want to preserve storage, which contains metadata and information
# from Kubeflow Pipelines:
kfctl delete -f ${CONFIG_FILE}

kubectl delete mutatingwebhookconfigurations --all
kubectl delete validatingwebhookconfigurations --all
kubectl delete crd --all
kubectl patch crd/profiles.kubeflow.org -p '{"metadata":{"finalizers":[]}}' --type=merge
```
# 4. 问题


## 4.1. Notebook 的存储问题

通过istio-ingressgateway访问Kubeflow Dashboard，进入notebook提示一个错误

```shell
No default Storage Class is set. Can’t create new Disks for the new Notebook. Please use an Existing Disk
```

原因是没有配置默认的StorageClass

解决
使用nfs作为provisioner，先安装插件

apiVersion: v1
kind: ServiceAccount
metadata:
  4.2. name: nfs-client-provisioner
---
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: nfs-provisioner
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: nfs-provisioner
    spec:
      serviceAccount: nfs-client-provisioner
      containers:
        - name: nfs-provisioner
          image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: kubeflow/nfs
            - name: NFS_SERVER
              value: 172.18.43.250
            - name: NFS_PATH
              value: /ssd/nfsdata/kubeflow/defstor
      volumes:
        - name: nfs-client-root
          nfs:
            server: 172.18.43.250
            path: /ssd/nfsdata/kubeflow/defstor


集群使用了rbac，则需要创建。注意，这里的namespace如果不存在，要先创建

kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    namespace: kubeflow-anonymous
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  4.3. apiGroup: rbac.authorization.k8s.io
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
verbs: ["list", "watch", "create", "update", "patch"]

创建StorageClass

apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: kubeflow-nfs-storage
provisioner: kubeflow/nfs


将新创建的StorageClass设为默认

```shell
kubectl patch storageclass <storageclass--name> -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'


kubectl patch storageclass kubeflow-nfs-storage -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
```

再次进入notebook不报错了


## 4.4. 2


**问题1**：安装的时候，一班需要多次运行kfctl apply命令出现如下问题
```shell
WARN[0598] Encountered error applying application tf-job-crds:  (kubeflow.error): Code 500 with message: Apply.Run  Error error when applying patch:
............
for: "/tmp/kout686424655": CustomResourceDefinition.apiextensions.k8s.io "tfjobs.kubeflow.org" is invalid: [spec.version: Invalid value: "v1beta1": must match the first version in spec.versions, status.storedVersions[0]: Invalid value: "v1beta1": must appear in spec.versions]
```
我是通过先执行删除命令，之后又重新安装就可以了

```shell
kubectl kustomize  kustomize/tf-job-crds/ | kubectl delete -f -
kubectl kustomize  kustomize/tf-job-crds/ | kubectl apply -f -
```


```shell
kubectl patch mutatingwebhookconfiguration inferenceservice.serving.kubeflow.org --patch '{"webhooks":[{"name": "inferenceservice.kfserving-webhook-server.pod-mutator","objectSelector":{"matchExpressions":[{"key":"serving.kubeflow.org/inferenceservice", "operator": "Exists"}]}}]}'
```



```shell
cat << EOF > istio-io-health.yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: "default"
  namespace: "istio-io-health"
spec:
  mtls:
    mode: STRICT
EOF
kubectl apply -f istio-io-health.yaml
```



```shell
cat << EOF > profile.yaml
apiVersion: kubeflow.org/v1beta1
kind: Profile
metadata:
  name: haha
spec:
  owner:
    kind: User
    name: userid@email.com   # replace with the email of the user

  resourceQuotaSpec:    # resource quota can be set optionally
   hard:
     cpu: "2"
     memory: 2Gi
     requests.nvidia.com/gpu: "1"
     persistentvolumeclaims: "1"
     requests.storage: "5Gi"
EOF
kubectl create -f profile.yaml
kubectl apply -f profile.yaml  #if you are modifying the profile

```



# 5. 详细解读 kfctl_k8s_istio.yaml

`kfctl_k8s_istio.yaml`中包括44个applications（应用），每个应用通过
kustomizeConfig部署


```yml
apiVersion: kfdef.apps.kubeflow.org/v1
kind: KfDef
metadata:
  namespace: kubeflow
spec:
  applications:
  - kustomizeConfig:
      parameters:
      - name: namespace
        value: istio-system
      repoRef:
        name: manifests
        path: istio/istio-crds
    name: istio-crds
  - kustomizeConfig:
      parameters:
      - name: namespace
        value: istio-system
      repoRef:
        name: manifests
        path: istio/istio-install
    name: istio-install
  - kustomizeConfig:
      parameters:
      - name: namespace
        value: istio-system
      repoRef:
        name: manifests
        path: istio/cluster-local-gateway
    name: cluster-local-gateway
  - kustomizeConfig:
      parameters:
      - name: namespace
        value: istio-system
      repoRef:
        name: manifests
        path: istio/kfserving-gateway
    name: kfserving-gateway
  - kustomizeConfig:
      parameters:
      - name: clusterRbacConfig
        value: 'OFF'
      repoRef:
        name: manifests
        path: istio/istio
    name: istio
  - kustomizeConfig:
      parameters:
      - name: namespace
        value: istio-system
      repoRef:
        name: manifests
        path: istio/add-anonymous-user-filter
    name: add-anonymous-user-filter
  - kustomizeConfig:
      repoRef:
        name: manifests
        path: application/application-crds
    name: application-crds
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: application/application
    name: application
  - kustomizeConfig:
      parameters:
      - name: namespace
        value: cert-manager
      repoRef:
        name: manifests
        path: cert-manager/cert-manager-crds
    name: cert-manager-crds
  - kustomizeConfig:
      parameters:
      - name: namespace
        value: kube-system
      repoRef:
        name: manifests
        path: cert-manager/cert-manager-kube-system-resources
    name: cert-manager-kube-system-resources
  - kustomizeConfig:
      overlays:
      - self-signed
      - application
      parameters:
      - name: namespace
        value: cert-manager
      repoRef:
        name: manifests
        path: cert-manager/cert-manager
    name: cert-manager
  - kustomizeConfig:
      repoRef:
        name: manifests
        path: metacontroller
    name: metacontroller
  - kustomizeConfig:
      overlays:
      - istio
      - application
      repoRef:
        name: manifests
        path: argo
    name: argo
  - kustomizeConfig:
      repoRef:
        name: manifests
        path: kubeflow-roles
    name: kubeflow-roles
  - kustomizeConfig:
      overlays:
      - istio
      - application
      repoRef:
        name: manifests
        path: common/centraldashboard
    name: centraldashboard
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: admission-webhook/bootstrap
    name: bootstrap
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: admission-webhook/webhook
    name: webhook
  - kustomizeConfig:
      overlays:
      - istio
      - application
      parameters:
      - name: userid-header
        value: kubeflow-userid
      repoRef:
        name: manifests
        path: jupyter/jupyter-web-app
    name: jupyter-web-app
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: spark/spark-operator
    name: spark-operator
  - kustomizeConfig:
      overlays:
      - istio
      - application
      - db
      repoRef:
        name: manifests
        path: metadata
    name: metadata
  - kustomizeConfig:
      overlays:
      - istio
      - application
      repoRef:
        name: manifests
        path: jupyter/notebook-controller
    name: notebook-controller
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: pytorch-job/pytorch-job-crds
    name: pytorch-job-crds
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: pytorch-job/pytorch-operator
    name: pytorch-operator
  - kustomizeConfig:
      overlays:
      - application
      parameters:
      - name: namespace
        value: knative-serving
      repoRef:
        name: manifests
        path: knative/knative-serving-crds
    name: knative-crds
  - kustomizeConfig:
      overlays:
      - application
      parameters:
      - name: namespace
        value: knative-serving
      repoRef:
        name: manifests
        path: knative/knative-serving-install
    name: knative-install
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: kfserving/kfserving-crds
    name: kfserving-crds
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: kfserving/kfserving-install
    name: kfserving-install
  - kustomizeConfig:
      overlays:
      - application
      parameters:
      - name: usageId
        value: <randomly-generated-id>
      - name: reportUsage
        value: 'true'
      repoRef:
        name: manifests
        path: common/spartakus
    name: spartakus
  - kustomizeConfig:
      overlays:
      - istio
      repoRef:
        name: manifests
        path: tensorboard
    name: tensorboard
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: tf-training/tf-job-crds
    name: tf-job-crds
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: tf-training/tf-job-operator
    name: tf-job-operator
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: katib/katib-crds
    name: katib-crds
  - kustomizeConfig:
      overlays:
      - application
      - istio
      repoRef:
        name: manifests
        path: katib/katib-controller
    name: katib-controller
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: pipeline/api-service
    name: api-service
  - kustomizeConfig:
      overlays:
      - application
      parameters:
      - name: minioPvcName
        value: minio-pv-claim
      repoRef:
        name: manifests
        path: pipeline/minio
    name: minio
  - kustomizeConfig:
      overlays:
      - application
      parameters:
      - name: mysqlPvcName
        value: mysql-pv-claim
      repoRef:
        name: manifests
        path: pipeline/mysql
    name: mysql
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: pipeline/persistent-agent
    name: persistent-agent
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: pipeline/pipelines-runner
    name: pipelines-runner
  - kustomizeConfig:
      overlays:
      - istio
      - application
      repoRef:
        name: manifests
        path: pipeline/pipelines-ui
    name: pipelines-ui
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: pipeline/pipelines-viewer
    name: pipelines-viewer
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: pipeline/scheduledworkflow
    name: scheduledworkflow
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: pipeline/pipeline-visualization-service
    name: pipeline-visualization-service
  - kustomizeConfig:
      overlays:
      - application
      - istio
      parameters:
      - name: admin
        value: johnDoe@acme.com
      repoRef:
        name: manifests
        path: profiles
    name: profiles
  - kustomizeConfig:
      overlays:
      - application
      repoRef:
        name: manifests
        path: seldon/seldon-core-operator
    name: seldon-core-operator
  repos:
  - name: manifests
    uri: https://github.com/kubeflow/manifests/archive/v1.0.2.tar.gz
  version: v1.0.2
```






# 6. 参考资料 

1.[阿里云Kubeflow 1.0 上线： 体验生产级的机器学习平台
](https://developer.aliyun.com/article/758776)
2. [基于K8s 1.15部署kubeflow 0.7.0 by kfctl--问题集锦](https://blog.csdn.net/reachyu/article/details/105764805)