<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>2.为了更快的Spark - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#10-计算机科学">10-计算机科学</a>&nbsp;»&nbsp;<a href="/Wiki/#-04-Distributed_System">04-Distributed_System</a>&nbsp;»&nbsp;<a href="/Wiki/#-02-分布式计算系统">02-分布式计算系统</a>&nbsp;»&nbsp;<a href="/Wiki/#-02-Spark">02-Spark</a>&nbsp;»&nbsp;<a href="/Wiki/#-1-理论">1-理论</a>&nbsp;»&nbsp;<a href="/Wiki/#-01_核心原理">01_核心原理</a>&nbsp;»&nbsp;2.为了更快的Spark</div>
</div>
<div class="clearfix"></div>
<div id="title">2.为了更快的Spark</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#1">1. 原则</a></li>
<li><a href="#2">2. 实践</a><ul>
<li><a href="#21">2.1. 编程范式</a><ul>
<li><a href="#211-1rdd">2.1.1. 原则1：避免创建重复的RDD</a></li>
<li><a href="#212-2rdd">2.1.2. 原则2：尽可能复用同一个RDD</a></li>
<li><a href="#213-3rdd">2.1.3. 原则3：对多次使用的RDD进行持久化</a></li>
<li><a href="#214-4shuffle">2.1.4. 原则4：尽量避免使用shuffle类算子</a></li>
<li><a href="#215-5map-sideshuffle">2.1.5. 原则5：使用map-side预聚合的shuffle操作</a></li>
<li><a href="#216-6">2.1.6. 原则6：使用高性能的算子</a></li>
<li><a href="#217-7">2.1.7. 原则7：广播大变量</a></li>
<li><a href="#218-8kryo">2.1.8. 原则8：使用Kryo优化序列化性能</a></li>
<li><a href="#219-9">2.1.9. 原则9：优化数据结构</a></li>
</ul>
</li>
<li><a href="#22">2.2. 资源参数调优</a><ul>
<li><a href="#221-num-executors">2.2.1. num-executors</a></li>
<li><a href="#222-sparkexecutormemory">2.2.2. spark.executor.memory</a></li>
<li><a href="#223-sparkexecutorcores">2.2.3. spark.executor.cores</a></li>
<li><a href="#224-sparkdrivermemory">2.2.4. spark.driver.memory</a></li>
<li><a href="#225-sparkdefaultparallelism">2.2.5. spark.default.parallelism</a><ul>
<li><a href="#2251">2.2.5.1. 默认</a></li>
<li><a href="#2252">2.2.5.2. 读取数据源时的并行度</a><ul>
<li><a href="#22521">2.2.5.2.1. 从内存</a></li>
<li><a href="#22522">2.2.5.2.2. 从文件</a></li>
<li><a href="#22523">2.2.5.2.3. 从数据库</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#226-sparkstoragememoryfraction">2.2.6. spark.storage.memoryFraction</a></li>
<li><a href="#227-sparkshufflememoryfraction">2.2.7. spark.shuffle.memoryFraction</a></li>
<li><a href="#228-sparklocalitywait">2.2.8. spark.locality.wait</a></li>
</ul>
</li>
<li><a href="#23-fastutil">2.3. 使用fastutil优化数据格式</a></li>
<li><a href="#24-jvmexecutor">2.4. JVM调优之调节Executor堆外内存与连接等待时长</a></li>
</ul>
</li>
<li><a href="#3">3. 效果</a><ul>
<li><a href="#31">3.1. 受益于好的分区操作</a></li>
</ul>
</li>
<li><a href="#4">4. 参考资料</a></li>
</ul>
</div>
<h1 id="1">1. 原则</h1>
<p>提高计算并行度，降低IO消耗</p>
<p>参考资料:<br />
https://sparkbyexamples.com/spark/spark-performance-tuning/#coalesce</p>
<h1 id="2">2. 实践</h1>
<h2 id="21">2.1. 编程范式</h2>
<p>理解运行机制，并写好程序是最关键的</p>
<h3 id="211-1rdd">2.1.1. 原则1：避免创建重复的RDD</h3>
<p>通常来说，我们在开发一个Spark作业时，首先是基于某个数据源（比如Hive表或HDFS文件）创建一个初始的RDD；接着对这个RDD执行某个算子操作，然后得到下一个RDD；以此类推，循环往复，直到计算出最终我们需要的结果。在这个过程中，多个RDD会通过不同的算子操作（比如map、reduce等）串起来，这个<strong>RDD串</strong>，就是RDD lineage，也就是<strong>RDD的血缘关系链</strong>。</p>
<p>我们在开发过程中要注意：对于同一份数据，只应该创建一个RDD，不能创建多个RDD来代表同一份数据。</p>
<p>一些Spark初学者在刚开始开发Spark作业时，或者是有经验的工程师在开发RDD lineage极其冗长的Spark作业时，<strong>可能会忘了自己之前对于某一份数据已经创建过一个RDD了</strong>，从而导致对于同一份数据，创建了多个RDD。这就意味着，我们的Spark作业会进行多次重复计算来创建多个代表相同数据的RDD，进而增加了作业的性能开销。</p>
<div class="hlcode"><pre><span class="c1">// 反例 //</span>
<span class="k">val</span> <span class="n">rdd1</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;hdfs://192.168.0.1:9000/hello.txt&quot;</span><span class="o">)</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(...)</span>
<span class="k">val</span> <span class="n">rdd2</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;hdfs://192.168.0.1:9000/hello.txt&quot;</span><span class="o">)</span>
<span class="n">rdd2</span><span class="o">.</span><span class="n">reduce</span><span class="o">(...)</span>
<span class="c1">// 正例</span>
<span class="k">val</span> <span class="n">rdd1</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;hdfs://192.168.0.1:9000/hello.txt&quot;</span><span class="o">)</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(...)</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">reduce</span><span class="o">(...)</span>
</pre></div>


<h3 id="212-2rdd">2.1.2. 原则2：尽可能复用同一个RDD</h3>
<p>除了要避免在开发过程中对一份完全相同的数据创建多个RDD之外，在对不同的数据执行算子操作时还要尽可能地复用一个RDD。比如说，有一个RDD的数据格式是key-value类型的，另一个是单value类型的，这两个RDD的value数据是完全一样的。那么此时我们可以只使用key-value类型的那个RDD，因为其中已经包含了另一个的数据。对于类似这种多个RDD的数据有重叠或者包含的情况，我们应该尽量复用一个RDD，这样可以尽可能地减少RDD的数量，从而尽可能减少算子执行的次数。</p>
<p>一个简单的例子</p>
<div class="hlcode"><pre><span class="c1">// 错误的做法。</span>
<span class="c1">// 有一个&lt;Long, String&gt;格式的RDD，即rdd1。</span>
<span class="c1">// 接着由于业务需要，对rdd1执行了一个map操作，创建了一个rdd2，而rdd2中的数据仅仅是rdd1中的value值而已，也就是说，rdd2是rdd1的子集。</span>
<span class="n">rdd1</span> <span class="k">=</span> <span class="o">...</span>
<span class="n">rdd2</span> <span class="k">=</span> <span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(...)</span>

<span class="c1">// 分别对rdd1和rdd2执行了不同的算子操作。</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">reduceByKey</span><span class="o">(...)</span>
<span class="n">rdd2</span><span class="o">.</span><span class="n">map</span><span class="o">(...)</span>

<span class="c1">// 正确的做法。</span>

<span class="c1">// 上面这个case中，其实rdd1和rdd2的区别无非就是数据格式不同而已，rdd2的数据完全就是rdd1的子集而已，却创建了两个rdd，并对两个rdd都执行了一次算子操作。</span>
<span class="c1">// 此时会因为对rdd1执行map算子来创建rdd2，而多执行一次算子操作，进而增加性能开销。</span>

<span class="c1">// 其实在这种情况下完全可以复用同一个RDD。</span>
<span class="c1">// 我们可以使用rdd1，既做reduceByKey操作，也做map操作。</span>
<span class="c1">// 在进行第二个map操作时，只使用每个数据的tuple._2，也就是rdd1中的value值，即可。</span>
<span class="nc">JavaPairRDD</span><span class="o">&lt;</span><span class="nc">Long</span><span class="o">,</span> <span class="nc">String</span><span class="o">&gt;</span> <span class="n">rdd1</span> <span class="k">=</span> <span class="o">...</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">reduceByKey</span><span class="o">(...)</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">tuple</span><span class="o">.</span><span class="n">_2</span><span class="o">...)</span>

<span class="c1">// 第二种方式相较于第一种方式而言，很明显减少了一次rdd2的计算开销。</span>
<span class="c1">// 但是到这里为止，优化还没有结束，对rdd1我们还是执行了两次算子操作，rdd1实际上还是会被计算两次。</span>
<span class="c1">// 因此还需要配合“原则三：对多次使用的RDD进行持久化”进行使用，才能保证一个RDD被多次使用时只被计算一次。</span>
</pre></div>


<h3 id="213-3rdd">2.1.3. 原则3：对多次使用的RDD进行持久化</h3>
<p>当你在Spark代码中多次对一个RDD做了算子操作后，恭喜，你已经实现Spark作业第一步的优化了，也就是尽可能复用RDD。此时就该在这个基础之上，进行第二步优化了，也就是要保证对一个RDD执行多次算子操作时，这个RDD本身仅仅被计算一次。</p>
<p>Spark中对于一个RDD执行多次算子的默认原理是这样的：每次你对一个RDD执行一个算子操作时，都会重新从源头处计算一遍，计算出那个RDD来，然后再对这个RDD执行你的算子操作。这种方式的性能是很差的。</p>
<p>因此对于这种情况，我们的建议是：对多次使用的RDD进行持久化。此时Spark就会根据你的持久化策略，将RDD中的数据保存到内存或者磁盘中。以后每次对这个RDD进行算子操作时，都会直接从内存或磁盘中提取持久化的RDD数据，然后执行算子，而不会从源头处重新计算一遍这个RDD，再执行算子操作。</p>
<p>对多次使用的RDD进行持久化的代码示例</p>
<div class="hlcode"><pre><span class="c1">// 如果要对一个RDD进行持久化，只要对这个RDD调用cache()和persist()即可。</span>

<span class="c1">// 正确的做法。</span>
<span class="c1">// cache()方法表示：使用非序列化的方式将RDD中的数据全部尝试持久化到内存中。</span>
<span class="c1">// 此时再对rdd1执行两次算子操作时，只有在第一次执行map算子时，才会将这个rdd1从源头处计算一次。</span>
<span class="c1">// 第二次执行reduce算子时，就会直接从内存中提取数据进行计算，不会重复计算一个rdd。</span>
<span class="k">val</span> <span class="n">rdd1</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;hdfs://192.168.0.1:9000/hello.txt&quot;</span><span class="o">).</span><span class="n">cache</span><span class="o">()</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(...)</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">reduce</span><span class="o">(...)</span>

<span class="c1">// persist()方法表示：手动选择持久化级别，并使用指定的方式进行持久化。</span>
<span class="c1">// 比如说，StorageLevel.MEMORY_AND_DISK_SER表示，内存充足时优先持久化到内存中，内存不充足时持久化到磁盘文件中。</span>
<span class="c1">// 而且其中的_SER后缀表示，使用序列化的方式来保存RDD数据，此时RDD中的每个partition都会序列化成一个大的字节数组，然后再持久化到内存或磁盘中。</span>
<span class="c1">// 序列化的方式可以减少持久化的数据对内存/磁盘的占用量，进而避免内存被持久化数据占用过多，从而发生频繁GC。</span>
<span class="k">val</span> <span class="n">rdd1</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;hdfs://192.168.0.1:9000/hello.txt&quot;</span><span class="o">).</span><span class="n">persist</span><span class="o">(</span><span class="nc">StorageLevel</span><span class="o">.</span><span class="nc">MEMORY_AND_DISK_SER</span><span class="o">)</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(...)</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">reduce</span><span class="o">(...)</span>
<span class="n">对于persist</span><span class="o">()</span><span class="n">方法而言</span><span class="err">，</span><span class="n">我们可以根据不同的业务场景选择不同的持久化级别</span><span class="err">。</span>
</pre></div>


<h3 id="214-4shuffle">2.1.4. 原则4：尽量避免使用shuffle类算子</h3>
<p>如果有可能的话，要尽量避免使用shuffle类算子。因为Spark作业运行过程中，最消耗性能的地方就是shuffle过程。shuffle过程，简单来说，就是将分布在集群中多个节点上的同一个key，拉取到同一个节点上，进行聚合或join等操作。比如reduceByKey、join等算子，都会触发shuffle操作。</p>
<p>shuffle过程中，各个节点上的相同key都会先写入本地磁盘文件中，然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同key。而且相同key都拉取到同一个节点进行聚合操作时，还有可能会因为一个节点上处理的key过多，导致内存不够存放，进而溢写到磁盘文件中。因此在shuffle过程中，可能会发生大量的磁盘文件读写的IO操作，以及数据的网络传输操作。磁盘IO和网络数据传输也是shuffle性能较差的主要原因。</p>
<p>因此在我们的开发过程中，能避免则尽可能避免使用<code>reduceByKey</code>、<code>join</code>、<code>distinct</code>、<code>repartition</code>等会进行shuffle的算子，尽量使用map类的非shuffle算子。这样的话，没有shuffle操作或者仅有较少shuffle操作的Spark作业，可以大大减少性能开销。</p>
<p>Broadcast与map进行join代码示例</p>
<div class="hlcode"><pre><span class="c1">// 传统的join操作会导致shuffle操作。</span>
<span class="c1">// 因为两个RDD中，相同的key都需要通过网络拉取到一个节点上，由一个task进行join操作。</span>
<span class="k">val</span> <span class="n">rdd3</span> <span class="k">=</span> <span class="n">rdd1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">rdd2</span><span class="o">)</span>
<span class="c1">// Broadcast+map的join操作，不会导致shuffle操作。</span>
<span class="c1">// 使用Broadcast将一个数据量较小的RDD作为广播变量。</span>
<span class="k">val</span> <span class="n">rdd2Data</span> <span class="k">=</span> <span class="n">rdd2</span><span class="o">.</span><span class="n">collect</span><span class="o">()</span>
<span class="k">val</span> <span class="n">rdd2DataBroadcast</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">broadcast</span><span class="o">(</span><span class="n">rdd2Data</span><span class="o">)</span>
<span class="c1">// 在rdd1.map算子中，可以从rdd2DataBroadcast中，获取rdd2的所有数据。</span>
<span class="c1">// 然后进行遍历，如果发现rdd2中某条数据的key与rdd1的当前数据的key是相同的，那么就判定可以进行join。</span>
<span class="c1">// 此时就可以根据自己需要的方式，将rdd1当前数据与rdd2中可以连接的数据，拼接在一起（String或Tuple）。</span>
<span class="k">val</span> <span class="n">rdd3</span> <span class="k">=</span> <span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">rdd2DataBroadcast</span><span class="o">...)</span>

<span class="c1">// 注意，以上操作，建议仅仅在rdd2的数据量比较少（比如几百M，或者一两G）的情况下使用。</span>
<span class="c1">// 因为每个Executor的内存中，都会驻留一份rdd2的全量数据。</span>
</pre></div>


<h3 id="215-5map-sideshuffle">2.1.5. 原则5：使用map-side预聚合的shuffle操作</h3>
<p>如果因为业务需要，一定要使用shuffle操作，无法用map类的算子来替代，那么尽量使用可以map-side预聚合的算子。</p>
<p>所谓的map-side预聚合，说的是在每个节点本地对相同的key进行一次聚合操作，类似于MapReduce中的本地combiner。map-side预聚合之后，每个节点本地就只会有一条相同的key，因为多条相同的key都被聚合起来了。其他节点在拉取所有节点上的相同key时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘IO以及网络传输开销。通常来说，在可能的情况下，建议使用reduceByKey或者aggregateByKey算子来替代掉groupByKey算子。因为reduceByKey和aggregateByKey算子都会使用用户自定义的函数对每个节点本地的相同key进行预聚合。而groupByKey算子是不会进行预聚合的，全量的数据会在集群的各个节点之间分发和传输，性能相对来说比较差。</p>
<p>比如如下两幅图，就是典型的例子，分别基于<code>reduceByKey</code>和<code>groupByKey</code>进行单词计数。其中第一张图是<code>groupByKey</code>的原理图，可以看到，没有进行任何本地聚合时，所有数据都会在集群节点之间传输；第二张图是reduceByKey的原理图，可以看到，每个节点本地的相同key数据，都进行了预聚合，然后才传输到其他节点上进行全局聚合。</p>
<h3 id="216-6">2.1.6. 原则6：使用高性能的算子</h3>
<p>除了shuffle相关的算子有优化原则之外，其他的算子也都有着相应的优化原则。</p>
<ol>
<li>
<p>使用<code>reduceByKey</code>/<code>aggregateByKey</code>替代groupByKey</p>
<blockquote>
<p>详情见“原则五：使用map-side预聚合的shuffle操作”。</p>
</blockquote>
</li>
<li>
<p>使用<code>mapPartitions</code>替代普通<code>map</code></p>
<blockquote>
<p>mapPartitions类的算子，一次函数调用会处理一个partition所有的数据，而不是一次函数调用处理一条，性能相对来说会高一些。但是有的时候，使用mapPartitions会出现OOM（内存溢出）的问题。因为单次函数调用就要处理掉一个partition所有的数据，如果内存不够，垃圾回收时是无法回收掉太多对象的，很可能出现OOM异常。所以使用这类操作时要慎重！</p>
</blockquote>
</li>
<li>
<p>使用<code>foreachPartitions</code>替代<code>foreach</code></p>
<blockquote>
<p>原理类似于“使用mapPartitions替代map”，也是一次函数调用处理一个partition的所有数据，而不是一次函数调用处理一条数据。在实践中发现，foreachPartitions类的算子，对性能的提升还是很有帮助的。比如在foreach函数中，将RDD中所有数据写MySQL，那么如果是普通的foreach算子，就会一条数据一条数据地写，每次函数调用可能就会创建一个数据库连接，此时就势必会频繁地创建和销毁数据库连接，性能是非常低下；但是如果用foreachPartitions算子一次性处理一个partition的数据，那么对于每个partition，只要创建一个数据库连接即可，然后执行批量插入操作，此时性能是比较高的。实践中发现，对于1万条左右的数据量写MySQL，性能可以提升30%以上。</p>
</blockquote>
</li>
<li>
<p>使用<code>filter</code>之后进行<code>coalesce</code>操作</p>
<blockquote>
<p>通常对一个RDD执行filter算子过滤掉RDD中较多数据后（比如30%以上的数据），建议使用coalesce算子，手动减少RDD的partition数量，将RDD中的数据压缩到更少的partition中去。因为filter之后，RDD的每个partition中都会有很多数据被过滤掉，此时如果照常进行后续的计算，其实每个task处理的partition中的数据量并不是很多，有一点资源浪费，而且此时处理的task越多，可能速度反而越慢。因此用coalesce减少partition数量，将RDD中的数据压缩到更少的partition之后，只要使用更少的task即可处理完所有的partition。在某些场景下，对于性能的提升会有一定的帮助。</p>
</blockquote>
</li>
<li>
<p>使用<code>repartitionAndSortWithinPartitions</code>替代<code>repartition</code>与<code>sort</code>类操作</p>
<blockquote>
<p>repartitionAndSortWithinPartitions是Spark官网推荐的一个算子，官方建议，如果需要在repartition重分区之后，还要进行排序，建议直接使用repartitionAndSortWithinPartitions算子。因为该算子可以一边进行重分区的shuffle操作，一边进行排序。shuffle与sort两个操作同时进行，比先shuffle再sort来说，性能可能是要高的。</p>
</blockquote>
</li>
</ol>
<h3 id="217-7">2.1.7. 原则7：广播大变量</h3>
<p>有时在开发过程中，会遇到需要在算子函数中使用外部变量的场景（尤其是大变量，比如100M以上的大集合），那么此时就应该使用Spark的广播（Broadcast）功能来提升性能。</p>
<p>在算子函数中使用到外部变量时，默认情况下，Spark会将该变量复制多个副本，通过网络传输到task中，此时每个task都有一个变量副本。如果变量本身比较大的话（比如100M，甚至1G），那么大量的变量副本在网络中传输的性能开销，以及在各个节点的Executor中占用过多内存导致的频繁GC，都会极大地影响性能。</p>
<p>因此对于上述情况，如果使用的外部变量比较大，建议使用Spark的广播功能，对该变量进行广播。广播后的变量，会保证每个Executor的内存中，只驻留一份变量副本，而Executor中的task执行时共享该Executor中的那份变量副本。这样的话，可以大大减少变量副本的数量，从而减少网络传输的性能开销，并减少对Executor内存的占用开销，降低GC的频率。</p>
<p>广播大变量的代码示例</p>
<div class="hlcode"><pre><span class="c1">// 以下代码在算子函数中，使用了外部的变量。</span>
<span class="c1">// 此时没有做任何特殊操作，每个task都会有一份list1的副本。</span>
<span class="k">val</span> <span class="n">list1</span> <span class="k">=</span> <span class="o">...</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">list1</span><span class="o">...)</span>

<span class="c1">// 以下代码将list1封装成了Broadcast类型的广播变量。</span>
<span class="c1">// 在算子函数中，使用广播变量时，首先会判断当前task所在Executor内存中，是否有变量副本。</span>
<span class="c1">// 如果有则直接使用；如果没有则从Driver或者其他Executor节点上远程拉取一份放到本地Executor内存中。</span>
<span class="c1">// 每个Executor内存中，就只会驻留一份广播变量副本。</span>
<span class="k">val</span> <span class="n">list1</span> <span class="k">=</span> <span class="o">...</span>
<span class="k">val</span> <span class="n">list1Broadcast</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">broadcast</span><span class="o">(</span><span class="n">list1</span><span class="o">)</span>
<span class="n">rdd1</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">list1Broadcast</span><span class="o">...)</span>
</pre></div>


<h3 id="218-8kryo">2.1.8. 原则8：使用Kryo优化序列化性能</h3>
<p>在Spark中，主要有3个地方涉及到了序列化： <br />
1. 在算子函数中使用到外部变量时，该变量会被序列化后进行<strong>网络传输</strong>（见“原则七：广播大变量”中的讲解）。 <br />
2. 将自定义的类型作为RDD的泛型类型时（比如JavaRDD，Student是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现Serializable接口。 <br />
3. 使用可序列化的持久化策略时（比如MEMORY_ONLY_SER），Spark会将RDD中的每个partition都序列化成一个大的字节数组。</p>
<p>默认情况下，Spark内部是使用Java的序列化机制，ObjectOutputStream/ObjectInputStream，对象输入输出流机制，来进行序列化。<br />
<strong>优点</strong>：处理起来比较方便，只是在算子里面使用的变量，必须是实现Serializable接口的。<br />
<strong>缺点</strong>：默认的序列化机制的效率不高，序列化的速度比较慢；序列化以后的数据，占用的内存空间相对还是比较大。</p>
<p>Kryo序列化机制，比默认的Java序列化机制，速度要快，序列化后的数据要更小，大概是Java序列化机制的1/10。</p>
<p>Spark之所以默认没有使用Kryo作为序列化类库，是因为Kryo要求最好要注册所有需要进行序列化的自定义类型，因此对于开发者来说，这种方式比较麻烦。</p>
<p>以下是使用Kryo的代码示例，我们只要设置序列化类，再注册要序列化的自定义类型即可（比如算子函数中使用到的外部变量类型、作为RDD泛型类型的自定义类型等）：</p>
<div class="hlcode"><pre><span class="c1">// 创建SparkConf对象。</span>
<span class="k">val</span> <span class="n">conf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="o">().</span><span class="n">setMaster</span><span class="o">(...).</span><span class="n">setAppName</span><span class="o">(...)</span>
<span class="c1">// 设置序列化器为KryoSerializer。</span>
<span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.serializer&quot;</span><span class="o">,</span> <span class="s">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span><span class="o">)</span>
<span class="c1">// 注册要序列化的自定义类型。</span>
<span class="n">conf</span><span class="o">.</span><span class="n">registerKryoClasses</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">classOf</span><span class="o">[</span><span class="kt">MyClass1</span><span class="o">],</span> <span class="n">classOf</span><span class="o">[</span><span class="kt">MyClass2</span><span class="o">]))</span>
</pre></div>


<h3 id="219-9">2.1.9. 原则9：优化数据结构</h3>
<p>Java中，有三种类型比较耗费内存： <br />
1. 对象，每个Java对象都有对象头、引用等额外的信息，因此比较占用内存空间。 <br />
2. 字符串，每个字符串内部都有一个字符数组以及长度等额外信息。 <br />
3. 集合类型，比如HashMap、LinkedList等，因为集合类型内部通常会使用一些内部类来封装集合元素，比如Map.Entry。</p>
<p>因此Spark官方建议，在Spark编码实现中，特别是<strong>对于算子函数中的代码</strong>，尽量不要使用上述三种数据结构，尽量使用字符串替代对象，使用原始类型（比如Int、Long）替代字符串，使用数组替代集合类型，这样尽可能地减少内存占用，从而降低GC频率，提升性能。</p>
<p>但是在笔者的编码实践中发现，要做到该原则其实并不容易。因为我们同时要考虑到代码的可维护性，如果一个代码中，完全没有任何对象抽象，全部是字符串拼接的方式，那么对于后续的代码维护和修改，无疑是一场巨大的灾难。同理，如果所有操作都基于数组实现，而不使用HashMap、LinkedList等集合类型，那么对于我们的编码难度以及代码可维护性，也是一个极大的挑战。因此笔者建议，<strong>在可能以及合适的情况下，使用占用内存较少的数据结构，但是前提是要保证代码的可维护性。</strong></p>
<h2 id="22">2.2. 资源参数调优</h2>
<p>在开发完Spark作业之后，就该为作业配置合适的资源了。Spark的资源参数，基本都可以在spark-submit命令中作为参数设置。很多Spark初学者，通常不知道该设置哪些必要的参数，以及如何设置这些参数，最后就只能胡乱设置，甚至压根儿不设置。资源参数设置的不合理，可能会导致没有充分利用集群资源，作业运行会极其缓慢；或者设置的资源过大，队列没有足够的资源来提供，进而导致各种异常。总之，无论是哪种情况，都会导致Spark作业的运行效率低下，甚至根本无法运行。因此我们必须对Spark作业的资源使用原理有一个清晰的认识，并知道在Spark作业运行过程中，有哪些资源参数是可以设置的，以及如何设置合适的参数值。</p>
<p>了解完了Spark作业运行的基本原理之后，对资源相关的参数就容易理解了。所谓的Spark资源参数调优，其实主要就是对Spark运行过程中各个使用资源的地方，通过调节各种参数，来优化资源使用的效率，从而提升Spark作业的执行性能。以下参数就是Spark中主要的资源参数，每个参数都对应着作业运行原理中的某个部分，我们同时也给出了一个调优的参考值。</p>
<h3 id="221-num-executors">2.2.1. num-executors</h3>
<p>参数说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行。Driver在向YARN集群管理器申请资源时，YARN集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的Executor进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的Executor进程，此时你的Spark作业的运行速度是非常慢的。<br />
参数调优建议：<strong>每个Spark作业的运行一般设置50~100个左右的Executor进程比较合适</strong>，设置太少或太多的Executor进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。</p>
<div class="hlcode"><pre><span class="n">executor</span> <span class="err">数量</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">cores</span><span class="p">.</span><span class="n">max</span><span class="o">/</span><span class="n">spark</span><span class="p">.</span><span class="n">executor</span><span class="p">.</span><span class="n">cores</span>
</pre></div>


<p><code>spark.cores.max</code> 是指你的spark程序需要的总核数<br />
<code>spark.executor.cores</code> 是指每个executor需要的核数<br />
<code>spark.executor.instances</code> executor 数量</p>
<h3 id="222-sparkexecutormemory">2.2.2. spark.executor.memory</h3>
<p>参数说明：该参数用于设置每个Executor进程的内存。Executor内存的大小，很多时候直接决定了Spark作业的性能，而且跟常见的JVM OOM异常，也有直接的关联。<br />
参数调优建议：<strong>每个Executor进程的内存设置4G~8G较为合适</strong>。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，<strong>num-executors 乘以 executor-memory，是不能超过队列的最大内存量的</strong>。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的1/3~1/2，避免你自己的Spark作业占用了队列所有的资源，导致别的同学的作业无法运行。</p>
<h3 id="223-sparkexecutorcores">2.2.3. spark.executor.cores</h3>
<p>参数说明：该参数用于设置每个Executor进程的CPU core数量。这个参数决定了每个Executor进程并行执行task线程的能力。因为每个CPU core同一时间只能执行一个task线程，因此每个Executor进程的CPU core数量越多，越能够快速地执行完分配给自己的所有task线程。<br />
参数调优建议：<strong>Executor的CPU core数量设置为2~4个较为合适</strong>。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大CPU core限制是多少，再依据设置的Executor数量，来决定每个Executor进程可以分配到几个CPU core。同样建议，如果是跟他人共享这个队列，那么<strong>num-executors * executor-cores不要超过队列总CPU core的1/3~1/2</strong> 左右比较合适，也是避免影响其他同学的作业运行。</p>
<h3 id="224-sparkdrivermemory">2.2.4. spark.driver.memory</h3>
<p>参数说明：该参数用于设置Driver进程的内存。<br />
参数调优建议：Driver的内存通常来说不设置，或者<strong>设置1G左右应该</strong>就够了。</p>
<p>唯一需要注意的一点是，如果需要使用<code>collect</code>算子将RDD的数据全部拉取到Driver上进行处理，那么必须确保Driver的内存足够大，否则会出现OOM内存溢出的问题。</p>
<h3 id="225-sparkdefaultparallelism">2.2.5. spark.default.parallelism</h3>
<p>并行度：Spark作业中，各个stage的task数量，也就代表了Spark作业的在各个阶段（stage）的并行度。</p>
<p>官方推荐，task数量设置成<code>spark application</code><strong>总cpu core数量的2~3倍</strong>，比如150个cpu core，基本要设置task数量为300~500。</p>
<p>在spark设置并行度一般通过两种方式来设置：<br />
1. spark.default.parrallelism<br />
2. textFile()传入第二个参数，指定partition数量</p>
<div class="hlcode"><pre><span class="n">SparkConf</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">SparkConf</span><span class="o">()</span>
  <span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="s">&quot;spark.default.parallelism&quot;</span><span class="o">,</span> <span class="s">&quot;500&quot;</span><span class="o">)</span>
</pre></div>


<p>参数说明：该参数用于设置每个stage的默认task数量。Task是Spark中最新的执行单元。RDD一般是带有partitions的，每个partition的在一个executor上的执行可以任务是一个Task。这个参数极为重要，如果不设置可能会直接影响你的Spark作业性能。<br />
参数调优建议：<strong>Spark作业的默认task数量为500~1000个较为合适</strong>。很多同学常犯的一个错误就是不去设置这个参数，那么此时就会导致Spark自己根据底层HDFS的block数量来设置task的数量，默认是一个HDFS block对应一个task。通常来说，Spark默认设置的数量是偏少的（比如就几十个task），如果task数量偏少的话，就会导致你前面设置好的Executor的参数都前功尽弃。试想一下，<strong>无论你的Executor进程有多少个，内存和CPU有多大，但是task只有1个或者10个，那么90%的Executor进程可能根本就没有task执行</strong>，也就是白白浪费了资源！因此Spark官网建议的设置原则是，<strong>设置该参数为num-executors * executor-cores的2~3倍较为合适</strong>，比如Executor的总CPU core数量为300个，那么设置1000个task是可以的，此时可以充分地利用Spark集群的资源。</p>
<h4 id="2251">2.2.5.1. 默认</h4>
<p>没有配置<code>spark.default.parallelism</code>时，使用默认值<br />
spark-shell里的值等于cpu的核数</p>
<h4 id="2252">2.2.5.2. 读取数据源时的并行度</h4>
<h5 id="22521">2.2.5.2.1. 从内存</h5>
<p><code>sc.parallelize()</code>创建RDD<br />
默认分区数等于sc.defaultParallelism，指定参数时分区数值等于参数值。<br />
<code>spark.createDataFrame(data)</code>创建DataFrame<br />
当data的长度小于sc.defaultParallelism，分区数等于data长度，否则分区数等于sc.defaultParallelism</p>
<h5 id="22522">2.2.5.2.2. 从文件</h5>
<p><strong>本地文件</strong></p>
<div class="hlcode"><pre><span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">minPartitions</span><span class="p">)</span>
<span class="c">#分区为minPartitions</span>

<span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">()</span>
<span class="c">#分区为1 </span>
</pre></div>


<p><strong>hdfs文件</strong></p>
<p>用下面代码可以测试读取hdfs文件的分区数</p>
<div class="hlcode"><pre><span class="k">val</span> <span class="n">rdd</span> <span class="k">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;hdfs://ambari.master.com/data/egaosu/txt/20180416.txt&quot;</span><span class="o">)</span>
<span class="n">rdd</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">getNumPartitions</span>
<span class="c1">//rdd的默认分区数都为block数</span>
<span class="c1">//参数指定分区数时 最小为block数</span>
</pre></div>


<h5 id="22523">2.2.5.2.3. 从数据库</h5>
<p><strong>Hive表</strong><br />
默认根据hive表对应的hdfs的block,自动设置spark sql查询所在的那个stage的并行度。</p>
<p><strong>JBDC关系型数据库</strong></p>
<p>rdd 默认为1 </p>
<h3 id="226-sparkstoragememoryfraction">2.2.6. spark.storage.memoryFraction</h3>
<p>spark中，堆内存又被划分成了2块：<br />
1. 专门用来给RDD的cache、persist操作进行RDD数据缓存用的；<br />
2. 用来给spark算子函数的运行使用的，存放函数中自己创建的对象。</p>
<p>默认情况下，给RDD cache操作的内存占比是0.6，60%的内存都给了cache操作了。但是问题是，如果某些情况下，cache不是那么的紧张，问题在于task算子函数中创建的对象过多，然后内存又不太大，导致了频繁的minor gc，甚至频繁full gc，导致spark频繁的停止工作。性能影响会很大。</p>
<p>可以通过spark ui，如果是spark on yarn的话，那么就通过yarn的界面，去查看你的spark作业的运行统计。可以看到每个stage的运行情况，包括每个task的运行时间、gc时间等等。如果发现gc太频繁，时间太长。此时就可以适当调价这个比例。</p>
<p>降低cache操作的内存占比，大不了用persist操作，选择将一部分缓存的RDD数据写入磁盘，或者序列化方式，配合Kryo序列化类，减少RDD缓存的内存占用；降低cache操作内存占比；对应的，算子函数的内存占比就提升了。这个时候，可能，就可以减少minor gc的频率，同时减少full gc的频率。对性能的提升是有一定的帮助的。</p>
<p><code>spark.storage.memoryFraction，0.6 -&gt; 0.5 -&gt; 0.4 -&gt; 0.2</code></p>
<p>参数说明：该参数用于设置RDD持久化数据在Executor内存中能占的比例，默认是<strong>0.6</strong>。也就是说，默认Executor 60%的内存，可以用来保存持久化的RDD数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。</p>
<p>参数调优建议：如果Spark作业中，有较多的RDD持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果Spark作业中的shuffle类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的gc导致运行缓慢（通过spark web ui可以观察到作业的gc耗时），意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>
<h3 id="227-sparkshufflememoryfraction">2.2.7. spark.shuffle.memoryFraction</h3>
<p>参数说明：该参数用于设置shuffle过程中一个task拉取到上个stage的task的输出后，进行聚合操作时能够使用的Executor内存的比例，默认是<strong>0.2</strong>。也就是说，Executor默认只有20%的内存用来进行该操作。shuffle操作在进行聚合时，如果发现使用的内存超出了这个20%的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</p>
<p>参数调优建议：如果Spark作业中的RDD持久化操作较少，shuffle操作较多时，建议降低持久化操作的内存占比，提高shuffle操作的内存占比比例，避免shuffle过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的gc导致运行缓慢，意味着task执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p>
<p>资源参数的调优，没有一个固定的值，需要同学们根据自己的实际情况（包括Spark作业中的shuffle操作数量、RDD持久化操作数量以及spark web ui中显示的作业gc情况），同时参考本篇文章中给出的原理以及调优建议，合理地设置上述参数。</p>
<h3 id="228-sparklocalitywait">2.2.8. spark.locality.wait</h3>
<p>调节数据本地化等待时长<br />
<code>PROCESS_LOCAL &gt; NODE_LOCAL &gt; NO_PREF &gt; RACK_LOCAL &gt; ANY</code> Spark要对任务(task)进行分配的时候, 会计算出每个task要计算的是哪个分片的数据(partition)，Spark的task分配算法，会按照上面的顺序来进行分配。<br />
可能PROCESS_LOCAL节点的计算资源和计算能力都满了；<br />
Spark会等待一段时间，默认情况下是3s钟(不是绝对的，还有很多种情况，对不同的本地化级别，都会去等待)，到最后，就会选择一个比较差的本地化级别，比如说，将task分配到靠它要计算的数据所在节点，比较近的一个节点，然后进行计算。</p>
<ul>
<li><strong>何时调节这个参数</strong></li>
</ul>
<p>观察日志，spark作业的运行日志，先用client模式，在本地就直接可以看到比较全的日志。日志里面会显示，starting task...，PROCESS LOCAL、NODE LOCAL 如果是发现，好多的级别都是NODE_LOCAL、ANY，那么最好就去调节一下数据本地化的等待时长。调节完，应该是要反复调节，每次调节完以后，再来运行，观察日志 <code>spark.locality.wait</code>, 3s, 6s, 10s...</p>
<h2 id="23-fastutil">2.3. <a href="https://github.com/yangtong123/StudySpark#%E4%BD%BF%E7%94%A8fastutil%E4%BC%98%E5%8C%96%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F"></a>使用fastutil优化数据格式</h2>
<ul>
<li><strong>fastutil介绍</strong></li>
</ul>
<blockquote>
<p>fastutil是扩展了Java标准集合框架（Map、List、Set；HashMap、ArrayList、HashSet）的类库，提供了特殊类型的map、set、list和queue； fastutil能够提供更小的内存占用，更快的存取速度；我们使用fastutil提供的集合类，来替代自己平时使用的JDK的原生的Map、List、Set，好处在于，fastutil集合类，可以减小内存的占用，并且在进行集合的遍历、根据索引（或者key）获取元素的值和设置元素的值的时候，提供更快的存取速度； fastutil也提供了64位的array、set和list，以及高性能快速的，以及实用的IO类，来处理二进制和文本类型的文件</p>
</blockquote>
<p>fastutil的每一种集合类型，都实现了对应的Java中的标准接口（比如fastutil的map，实现了Java的Map接口），因此可以直接放入已有系统的任何代码中。fastutil还提供了一些JDK标准类库中没有的额外功能（比如双向迭代器）。</p>
<p>fastutil除了对象和原始类型为元素的集合，fastutil也提供引用类型的支持，但是对引用类型是使用等于号（=）进行比较的，而不是equals()方法。</p>
<ul>
<li>
<p><strong>Spark中应用fastutil的场景</strong></p>
</li>
<li>
<p>如果算子函数使用了外部变量；那么第一，你可以使用Broadcast广播变量优化；第二，可以使用Kryo序列化类库，提升序列化性能和效率；第三，如果外部变量是某种比较大的集合，那么可以考虑使用fastutil改写外部变量，首先从源头上就减少内存的占用，通过广播变量进一步减少内存占用，再通过Kryo序列化类库进一步减少内存占用。</p>
</li>
<li>
<p>在你的算子函数里，如果要创建比较大的Map、List等集合，可能会占用较大的内存空间，而且可能涉及到消耗性能的遍历、存取等集合操作；那么此时，可以考虑将这些集合类型使用fastutil类库重写，使用了fastutil集合类以后，就可以在一定程度上，减少task创建出来的集合类型的内存占用。避免executor内存频繁占满，频繁唤起GC，导致性能下降。</p>
</li>
</ul>
<div class="hlcode"><pre><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>it.unimi.dsi<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>fastutil<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>7.0.6<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</pre></div>


<blockquote>
<p><a href="https://github.com/yangtong123/StudySpark/blob/master/src/main/java/com/yt/spark/spark/session/UserVisitSessionAnalyzeSpark.java">UserVisitSessionAnalyzeSpark.java</a>中831行有示例。</p>
</blockquote>
<h2 id="24-jvmexecutor">2.4. <a href="https://github.com/yangtong123/StudySpark#jvm%E8%B0%83%E4%BC%98%E4%B9%8B%E8%B0%83%E8%8A%82executor%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E4%B8%8E%E8%BF%9E%E6%8E%A5%E7%AD%89%E5%BE%85%E6%97%B6%E9%95%BF"></a>JVM调优之调节Executor堆外内存与连接等待时长</h2>
<ul>
<li><strong>Executor堆外内存</strong></li>
</ul>
<p>有时候，如果你的spark作业处理的数据量特别特别大，几亿数据量；然后spark作业一运行，时不时的报错，shuffle file cannot find，executor、task lost，out of memory（内存溢出）</p>
<p>可能是说executor的堆外内存不太够用，导致executor在运行的过程中，可能会内存溢出；然后可能导致后续的stage的task在运行的时候，可能要从一些executor中去拉取shuffle map output文件， 但是executor可能已经挂掉了，关联的block manager也没有了；所以可能会报shuffle output file not found；resubmitting task；executor lost；spark作业彻底崩溃。</p>
<p><code>spark-submit</code>脚本里面，去用<code>--conf</code>的方式，去添加配置； 切记，不是在你的spark作业代码中，用<code>new SparkConf().set()</code>这种方式去设置，不要这样去设置，是没有用的！一定要在spark-submit脚本中去设置。</p>
<p>默认情况下，这个堆外内存上限大概是300多M；通常项目，真正处理大数据的时候，这里都会出现问题，导致spark作业反复崩溃，无法运行；此时就会去调节这个参数，到至少1G（1024M），甚至说2G、4G</p>
<ul>
<li><strong>连接等待时长</strong></li>
</ul>
<p>如果Executor远程从另一个Executor中拉取数据的时候，那个Executor正好在gc，此时呢，无法建立网络连接，会卡住；spark默认的网络连接的超时时长，是60s；如果卡住60s都无法建立连接的话，那么就宣告失败了。</p>
<p>碰到某某file。一串file id。uuid（dsfsfd-2342vs--sdf--sdfsd）。not found。file lost。很有可能是有那份数据的executor在jvm gc。所以拉取数据的时候，建立不了连接。然后超过默认60s以后，直接宣告失败。</p>
<p>spark-submit脚本，切记，不是在<code>new SparkConf().set()</code>这种方式来设置的。通常来说，可以避免部分的偶尔出现的某某文件拉取失败，某某文件lost</p>
<h1 id="3">3. 效果</h1>
<h2 id="31">3.1. 受益于好的分区操作</h2>
<p>The operations that benefit from partitioning are as follows:</p>
<div class="hlcode"><pre><span class="n">cogroup</span><span class="p">()</span>
<span class="n">groupWith</span><span class="p">()</span>
<span class="n">join</span><span class="p">()</span>
<span class="n">leftOuterJoin</span><span class="p">()</span>
<span class="n">rightOuterJoin</span><span class="p">()</span>
<span class="n">groupByKey</span><span class="p">()</span>
<span class="n">reduceByKey</span><span class="p">()</span>
<span class="n">combineByKey</span><span class="p">()</span>
<span class="n">partitionBy</span><span class="p">()</span>
<span class="n">sort</span><span class="p">()</span>
<span class="n">mapValues</span><span class="p">()</span> <span class="p">(</span><span class="k">if</span> <span class="n">the</span> <span class="n">parent</span> <span class="n">RDD</span> <span class="n">has</span> <span class="n">a</span> <span class="n">partitioner</span><span class="p">)</span>
<span class="n">flatMapValues</span><span class="p">()</span> <span class="p">(</span><span class="k">if</span> <span class="n">parent</span> <span class="n">has</span> <span class="n">a</span> <span class="n">partitioner</span><span class="p">)</span>
<span class="nb">filter</span><span class="p">()</span> <span class="p">(</span><span class="k">if</span> <span class="n">parent</span> <span class="n">has</span> <span class="n">a</span> <span class="n">partitioner</span><span class="p">)</span>
</pre></div>


<h1 id="4">4. 参考资料</h1>
<p>https://sparkbyexamples.com/spark/spark-performance-tuning/#coalesce</p>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2021 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>