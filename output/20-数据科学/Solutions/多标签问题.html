<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>多分类问题求解思路 - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#20-数据科学">20-数据科学</a>&nbsp;»&nbsp;<a href="/Wiki/#-Solutions">Solutions</a>&nbsp;»&nbsp;多分类问题求解思路</div>
</div>
<div class="clearfix"></div>
<div id="title">多分类问题求解思路</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#1">1. 引言</a></li>
<li><a href="#2-1">2. 定义[1]</a></li>
<li><a href="#3">3. 任务分解</a></li>
<li><a href="#4-calibration1">4. 阈值校准(Calibration)[1]</a><ul>
<li><a href="#401">4.0.1. 排序指标</a></li>
</ul>
</li>
</ul>
</div>
<p>其实A Review on Multi-Label Learning Algorithms也并不长，只有19页，而且还介绍得比较全面。Multi-Label 和传统的分类问题的区别主要在于多Label下，输出空间呈现指数级增长。那么目前对于Multi-Label的这类特性，学界一般是集中在更好的分析Label之间的相关性，就可以避免这种指数增长。主要的Strategy大致可以分为三类：</p>
<ol>
<li><code>First-Order Strategy</code>: 考虑的是label之间相互独立，那么就可以把Multi-label问题转换为普通的分类问题。如果一个Label有多类的话，那么就用传统的<code>One vs All(OvA)</code>来解决。</li>
<li><code>Second-Order Strategy</code>: 这一类是考虑Label之间的两两相关性，结果会导致计算复杂度有显著的增加。</li>
<li><code>High-Order Strategy</code>: 这个就是考虑多Label之间的相关性，计算复杂度会更高。目前有的一些分类算法：</li>
<li>Binary Relevance，如名字所写，这是一个First-Order Strategy；</li>
<li>Classifier Chains，把原问题分解成有先后顺序的一系列Binary Classification，然后前边的Binary Classification会对后边的产生影响；</li>
<li>Calibrated label ranking，这个有点像Multi-Classification中One vs One的策略，就是通过两两对比，然后进行投票决定分类效果。题主还是最开始提到的那篇论文吧，写得蛮全面的。</li>
</ol>
<h1 id="1">1. 引言</h1>
<p>真实世界中的分类任务有时候是多标签分类任务。本文系统总结了多标签分类学习，从它的定义和性质开始，到多标签学习的基本思想和经典算法，最后重点介绍了基于神经网络的多标签学习。</p>
<h1 id="2-1">2. 定义[1]</h1>
<p>多标签学习(MLL)研究的是一个样本由一个样例和一个集合的标签组成。假设 [公式] 表示 [公式] 样本空间， [公式] 表示标签空间。多标签学习的任务是从训练集 [公式] 学习一个函数 [公式] 。对于每个多标签样本 [公式] ， [公式]是一个 [公式] 维特征向量， [公式] 是标签集合。对于一个没见过的样本 [公式] ，多标签分类器 [公式] 预测 [公式] 作为该样本的标签集合。</p>
<h1 id="3">3. 任务分解</h1>
<p>MLL包括两个主要任务：<br />
1. 多标签分类(MLC)<br />
2. 标签排序(LR)。</p>
<p>MLC定义一个函数 [公式] 。给定一个样例，一个多标签分类器会返回一个相关的标签集合 [公式] ，和 [公式] 的补集 [公式] ，无关的标签集合。所以，也就产生了一个标签空间的二元划分。</p>
<p>LR定一个函数 [公式] 返回标签的相关性。</p>
<p>还有第三个任务，多标签排序，可以理解为MLC和LR的泛化，它同时产生一个二元划分和一致性(consistent)排序。话句话说，如果 [公式] 是 [公式] 相关的标签集合， [公式] 和 [公式] ，那么一致性排序会将 [公式] 中的标签比 [公式] 排得更高。从多标签排序角度定义的MLL可以从 [公式] 得到，其中 [公式] 是一个阈值函数。阈值函数的设定见下节。</p>
<h1 id="4-calibration1">4. 阈值校准(Calibration)[1]</h1>
<p>总的来说，阈值校准可以用两个策略实现，即设置 [公式] 为常量或从训练数据中推测。对于前者，由于 [公式] 是实值函数，所以讲 [公式] 设置为0就行了。或者当 [公式] 的输出为概率时， [公式] 设置为0.5。再或者，当测试集可见时，阈值可以设置为似的训练集和测试集的多标签程度指标区别最小的数。</p>
<p>对于后一个策略， stacking-style的步骤可以用来决定阈值函数。假设 [公式] 是一个线性模型，即 [公式] ，这里 [公式] 是一个 [公式] 维stacking向量。为了学习到 [公式]和 [公式] ，需要求解线性最小二乘：</p>
<p>[公式]</p>
<p>这里</p>
<p>[公式]</p>
<p>表示stacking模型的目标输出，它对每个样本，以最小误差将 [公式] 划分为相关和不相关。</p>
<p>上面的阈值校准策略是一般用途的计数，可以用在任何多标签学习算法得到的 [公式] 的后处理上。相应地，也有一些特别的阈值校准计数，是针对特定算法的。除了用阈值，另一个等效机制是为每个样本设置一个返回标签数量： [公式] ，那么 [公式] 。</p>
<ol>
<li>特点[1]<br />
相比于单标签分类，多标签分类有三个显著特点。</li>
</ol>
<p>5.1 不同数据集多标签的程度可能不同<br />
为了刻画多标签数据集的性质，几个有用的多标签指标可以使用。衡量多标签程度最自然的方式是标签基数(label cardinality)： [公式] ，即样本的平均标签数。相应地，标签密度用标签集大小来规范化标签基数： [公式] 。另一个常用衡量的多标签程度的指标是标签多样性(label diversity)： [公式] ，即数据集中不同的标签集合数。类似地，标签多样性可以用数据及大小规范化： [公式] 。</p>
<p>5.2 标签具有相互关系(corelation)<br />
从多标签数据集中学习的关键挑战在于难以控制的巨型输出空间，即，标签集合的数量随着类别数量指数及增长。因此，利用好标签之间的相互关系(或依赖)是必要的。比如，一张照片如果标记为热带雨林和足球，那么它标记为巴西的概率也会大；一篇文档如果标记为政治，就不太可能标记为娱乐。现有的标签相互关系利用的策略可大概分为三种，它们基于相互关系的级别进行划分：</p>
<p>一阶(first-order)策略: 多标签分类用一个标签一个标签的(label-by-label)方式处理，那么就忽略了其他标签的共存性，比如将多标签学习分解为若干个独立的二分类问题。一阶策略的主要价值在于概念上简单、效率高。另一方面。结果的有效性可能不是最好的。<br />
二阶策略：用标签之间的成对关系来处理。比如在相关和不相关的标签之间排序，或者任意两个标签之间的互动。结果可以取得不错的泛化表现。然而，有一些现实世界的问题的标签相互关系超越了二阶假设。<br />
高阶策略：考虑标签之间的高阶关系，比如将所有其他标签的影响施加到每个标签上，或寻找随机标签子集之间的关系，等等。高阶策略计算量大，可扩展性低。<br />
5.3 数据不平衡[2]<br />
可以从两个角度看。</p>
<p>一方面，某个类别的对应样例可能远多于另一个类别，这是类别之间不平衡(interclass)；某个类别对应的正样本可能远多于负样本，这是类别之内不平衡(innerclass)。</p>
<p>另一方面，从标签集合角度看，有的标签集合的样本相对多，有的相对少。</p>
<ol>
<li>评估指标[1]<br />
传统监督学习中，模型的表现用一些传统指标，比如准确率、F-score、AUC等等。而多标签学习的评估复杂很多，所以人们提出了一些专门给多标签学习的评估指标，可以大致分为两类，基于样例的[1.33][1.34][1.75]和基于标签的[1.94]。</li>
</ol>
<p>令 [公式] 为测试集， [公式] 为训练好的模型。基于样例的指标现在每一个测试样例上评估，然后计算所有样例的均值。基于标签的指标分别评估每个标签，然后返回所有标签的macro/micro均值。</p>
<p>关于 [公式] ，系统的泛化表现是从分类角度衡量的。然而，不管是基于样例的还是基于标签的指标，从函数 [公式] 角度衡量是更常见的操作。泛化表现也可以从排序角度衡量。下图总结了接下来要介绍的评估指标。</p>
<p>6.1 基于样例的指标<br />
6.1.1 子集准确率<br />
[公式]</p>
<p>其中， [公式] 是指示器函数。子集准确率衡量正确分类的样例的比例，即，预测标签集和真实标签集完全一样的比例。子集准确率可以看做传统准确率在多标签场景下的对应。一般来说这个指标过于严苛，尤其是标签空间很大的时候。</p>
<p>6.1.2 汉明损失<br />
[公式]</p>
<p>这里 [公式] 表示对等差分，是所有只在两个集合其中之一的元素组成的集合。</p>
<p>6.1.3 [公式]<br />
[公式]</p>
<p>[公式]</p>
<p>[公式]</p>
<p>[公式]</p>
<p>6.1.4 排序指标<br />
当 [公式] 可知时，四个基于样例的排序指标如下[1.75]：</p>
<p>One-error: [公式] 。one-error衡量排名第一的标签不是相关标签的比例。<br />
Coverage: [公式] coverage衡量了在排序标签列表上需要从头走多少步，才能覆盖全部相关的标签。<br />
Ranking Loss: [公式] 排序损失衡量了排序相反的比例，即不相关的标签排在相关标签之前。<br />
Average Precision: [公式] 平均精确度衡量了相关标签排在一个特定标签$y \in Y_i$之上的平均比例。<br />
6.2 基于标签的指标<br />
6.2.1 分类指标<br />
对于第 [公式] 个标签 [公式] ，有四个量表征二分类的表现： [公式]</p>
<p>[公式]</p>
<p>[公式]</p>
<p>[公式]</p>
<p>令 [公式] 表示一个具体的指标，根据这四个量，可以计算 [公式] ：</p>
<p>[公式]</p>
<p>[公式]</p>
<p>[公式]</p>
<p>[公式]</p>
<p>然后用所有标签的均值衡量 [公式] :</p>
<p>宏观平均： [公式]</p>
<p>微观平均： [公式]</p>
<p>宏观平均在标签上假设权重相等，微观平均在样例上假设权重相等。有：</p>
<p>[公式]</p>
<p>[公式]</p>
<h3 id="401">4.0.1. 排序指标</h3>
<p>宏观平均AUC:</p>
<p>[公式]</p>
<p>这里 [公式] 。</p>
<p>微观平均AUC：</p>
<p>[公式]</p>
<p>这里 [公式]</p>
<p>最后，不同指标衡量模型的不同方面。多标签模型应该用多种不同的指标综合评估。</p>
<ol>
<li>学习算法[1]<br />
多标签学习的算法可分为两种方法：</li>
</ol>
<p>问题转化方法 这类方法把多标签分类转化为其他成熟的场景。代表算法有一阶方法Binary Relevance[1.5]和高阶方法Classifier Chains[1.72] ，它们将多标签分类转化为二分类。二阶方法Calibrated Label Ranking[1.30] 将多标签分类转化为标签排序，高阶方法Random k-labelsets[1.94]将多标签学习转化为多分类问题。<br />
算法改编方法 这种方法改编流行的学习技术来应对多标签数据。代表性算法包括一阶方法ML-kNN[1.108]跟变k近邻 ，一阶方法ML-DT[1.16] 改编决策树，二阶方法Rank-SVM[1.27]改编核技巧，二阶方法CML[1.33] 改编information-theoretic techniques。<br />
简单说，问题转化就是让数据取适应算法，而算法改编就是让算法去适应数据。下面两图总结了这些算法。</p>
<p>7.1 问题转化方法<br />
7.1.1 Binary Relevance<br />
基本思想是将多标签学习问题分解为 [公式] 个独立的二分类问题，每个二分类问题对应一个标签空间中的标签。对于一个样本 [公式] ，Binary Relevance通过用各个二分类器计算每个标签的标签相关性预测它的标签集：</p>
<p>[公式]</p>
<p>评价：二元相关性是一阶方法。它的突出优点是处理多标签数据非常直接，成为了很多SOTA方法的基石。另一方面，二元相关性完全忽略标签之间潜在的相互关系，而且每个标签的二分类器可能受困于类别不平衡。</p>
<p>7.1.2 分类器链<br />
这个算法的基本思想是将多标签学习转化为一个链的二分类问题，其中链路上后续的二分类器建于前面二分类器的预测之上[1.72][1.73]。</p>
<p>对于 [公式] 个分类标签 [公式] ，令 [公式] 为一个排列函数，用于为标签定义一个顺序，即 [公式] 。对于排序列表的第 [公式] 的标签 [公式] ，相应的二分类训练集的构建方式是在样本后面拼接它对于 [公式] 之前的标签的相关性：</p>
<p>[公式]</p>
<p>这里， [公式] 是 [公式] 和 [公式] 的拼接， [公式] 表示 [公式] 之前的标签是否与 [公式] 相关，相关的位置是1，不相关的位置是0。然后，某个二分类学习算法 [公式] 用来训练一个二分类器 [公式] 。换句话说， [公式] 决定了 [公式] 是否相关。</p>
<p>对于新样本 [公式] ，它的标签集合通过迭代遍历分类器链来得到。令 [公式] 表示 [公式] 在 [公式] 上预测出的相关性，它可以递归推导：</p>
<p>[公式]</p>
<p>相应地，标签集合是：</p>
<p>[公式]</p>
<p>很明显， 效果很大程度上受排列 [公式] 影响。为了考虑进这点，可以用 [公式] 个排列的集成学习链。</p>
<p>评论：它是高阶方法，以随机的方式考虑所有标签的相互关系。与二元相关性相比，分类器链的有点是利用了标签相关性，但同时失去了并行实现的可能。</p>
<p>7.1.3 校准标签排序<br />
基本思想是将多标签分类转化为标签排序问题，标签的排序用逐对比较实现[1.30]。</p>
<p>对于 [公式] 个分类标签，有 [公式] 个二分类器用于成对比较。预测的时候用投票排序决定输出标签集合。</p>
<p>7.1.4 Random k-Labelsets<br />
将多标签分类转化为多分类的集成，每个成分学习器面向 [公式] 的一个子集，通过标签幂集(Label Powerset, LP)训练一个多分类器[1.92][1.94] 。</p>
<p>LP是一个将多标签学习问题转换为多类别分类问题的简单直接的方法。令 [公式] 为一个单射函数，将 [公式] 的幂集映射到自然数， [公式] 是对应的反函数。 训练阶段，LP首先将原来的数据集 [公式] 转换成下列多分类训练集：</p>
<p>[公式]</p>
<p>然后用某个多类别学习算法去学习。</p>
<p>不过，LP有两个主要限制实际应用的方面：(a)不完全。LP预测训练集中有的标签集合，但不能泛化新的标签集合。(b)不高效。当 [公式] 变大时，映射后的类别太多了。</p>
<p>为了保持LP的简洁性同时克服它的缺点，Random k-Labelsets选择结合集成学习和LP来学习多标签数据。关键策略是在随机k个标签集上使用LP来保证计算高效，然后集成几个LP分类器来达到完整性。</p>
<p>7.1.5 通过单标签学习方法来排序(ranking via single-label learning)[2]<br />
所谓单标签学习就是普通的与多标签学习相对的多分类学习。此方法将多标签数据集转换为单标签，然后用单标签分类器为每个标签打出一个分数，用来排序。一个直接的转换方式叫做ignore，它的数据集由忽略原数据集所有多标签的样例组成。这种方式很简单，但也损失了很多信息。</p>
<p>另一个方式叫做select，选择多标签中的一个标签，这也有信息损失。select-max选择最高频的标签，select-min选择最低频，select-random随机选择。</p>
<p>最后一个方式叫做copy，它将每个多标签样例复制多份，每个标签一份。如果给样例分配权重 [公式] ，就叫做copy-weight。这种方式没有信息损失，但它增加了模型决策边界的复杂度。</p>
<p>7.2 算法改编方法<br />
前文提到，k近邻、决策树、SVM等都可以改编到多标签分类。还有一类算法改变方法是神经网络改编算法，本文的重点是神经网络改编算法，所以略过传统机器学习改编算法。</p>
<ol>
<li>神经网络<br />
神经网络处理多标签学习也属于算法改编方法，因为是本文重点，所以单独列为一节。</li>
</ol>
<p>8.1 多标签多分类感知机(MMP)[2]<br />
Crammer[Crammer2003] 提出了多标签多分类感知机(MMP)算法。就像BR(二元相关性)那样，每个标签一个感知机，预测有内积计算。尽管如此，与独立学习每个类别的相关性不同的是， MMP一点一点地(incrementally)训练，产生一个实值相关性，将相关标签排序在不相关标签之前。所以，整体表现就是更新每个单个感知机。研究表明它高效、有竞争力，适合解决大规模多标签问题[Loza2007]。</p>
<p>8.2 MLL的反向传播[2]<br />
Zhang[Zhang2006]开发了MLL的反向传播(BP-MLL)，是传统多层前馈神经网络对多标签数据的改编。网络用梯度下降和误差反向传播训练，误差函数跟排序损失密切相关：</p>
<p>[公式]</p>
<p>其中， [公式] 是一个相关标签和一个表相关标签的分数之差。网络结构有3层。输入层有 [公式] 维，对应特征向量。输出层有 [公式] 个单元，对应 [公式] 个标签。</p>
<p>8.3 sigmoid激活函数+binary_crossentropy[3][4][5][6]<br />
普通的多分类神经网络中，输出层的激活函数是softmax，损失函数是交叉熵。</p>
<p>稍加修改，就可以支持多标签分类：</p>
<p>（1）输出层的激活函数不用softmax而是sigmoid。 [公式]</p>
<p>用sigmoid激活函数之后，输出层就将类别 [公式] 建模为伯努利概率分布[1]：</p>
<p>[公式]</p>
<p>现在每个类别的概率分布跟其他类别就是独立的了。阈值也可以设置成0.5。</p>
<p>（2）损失函数从普通categorical_crossentropy改成binary_crossentropy。</p>
<p>categorical_crossentropy简称CE，binary_crossentropy简称BCE。</p>
<p>CE公式：</p>
<p>[公式]</p>
<p>[公式] 第 [公式] 个类别对应的真实值(0或1)， [公式] 为模型对应的输出值。</p>
<p>BCE公式：</p>
<p>[公式]</p>
<p>CE是一个数值，而BCE是一个向量。BEC的第 [公式] 维表示 [公式] 产生的损失。在Keras中，用的是均值： [公式]</p>
<p>BEC相当于在每个类别上分别计算负对数概率。</p>
<p>这种方法跟前文提到的很多概念都有关系：</p>
<p>这是算法改编方法。<br />
它直接执行多标签排序任务，同时产生一个二元划分和一致性(consistent)排序。<br />
阈值校准直接将阈值设置为常量0.5。<br />
属于一阶策略，没有考虑标签之间的相互关系。<br />
没有考虑数据不平衡。<br />
很像多层感知机。相同之处是参数有标签数量个权重向量。不同之处是MMP没有激活函数，MMP的损失函数是误分类点到划分超平面的距离。<br />
有人用这种方法了改写了BERT文本分类[7][8]，在Kaggle的Toxic Comment Classification Challenge 中取得了不错的表现，甚至排名前10%。fastText也用了这种方法[17][18]。</p>
<p>8.4 将“softmax+交叉熵”推广到多标签分类问题<br />
作者是苏剑林。他表示，从形式上来看，单标签分类比多标签分类要容易，就是因为单标签有“softmax+交叉熵”可以用，它不会存在类别不平衡的问题，而多标签分类中的“sigmoid+交叉熵”就存在不平衡的问题。所以，理想的解决办法应该就是将“softmax+交叉熵”推广到多标签分类上去。这里的类别不均衡，指的是在多标签分类中，目标标签的个数比非目标标签的少得多。</p>
<p>作者将普通交叉熵改写为：</p>
<p>[公式]</p>
<p>并给出实现：</p>
<p>def multilabel_categorical_crossentropy(y_true, y_pred):<br />
    """多标签分类的交叉熵<br />
    说明：y_true和y_pred的shape一致，y_true的元素非0即1，<br />
         1表示对应的类为目标类，0表示对应的类为非目标类。<br />
    """<br />
    y_pred = (1 - 2 * y_true) * y_pred<br />
    y_pred_neg = y_pred - y_true * 1e12<br />
    y_pred_pos = y_pred - (1 - y_true) * 1e12<br />
    zeros = K.zeros_like(y_pred[..., :1])<br />
    y_pred_neg = K.concatenate([y_pred_neg, zeros], axis=-1)<br />
    y_pred_pos = K.concatenate([y_pred_pos, zeros], axis=-1)<br />
    neg_loss = K.logsumexp(y_pred_neg, axis=-1)<br />
    pos_loss = K.logsumexp(y_pred_pos, axis=-1)<br />
    return neg_loss + pos_loss<br />
至于为什么“softmax+交叉熵”能解决类别不平衡问题而“sigmoid+交叉熵”会存在类别不平衡问题，作者的解释是logsumexp自带平衡作用，会自动突出误差更大的项。</p>
<ol>
<li>扩展<br />
标签相互关系上，也有一些关于神经网络的工作[9][10]。</li>
</ol>
<p>除了普通的共现相互关系，还有人研究标签的层次关系[11][12][13][14][15][16]。</p>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2021 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>