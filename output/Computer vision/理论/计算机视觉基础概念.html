<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>计算机视觉基础 - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Computer vision\理论">Computer vision\理论</a>&nbsp;»&nbsp;计算机视觉基础</div>
</div>
<div class="clearfix"></div>
<div id="title">计算机视觉基础</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#1">1. 基本概念</a><ul>
<li><a href="#11">1.1. 图像</a><ul>
<li><a href="#111">1.1.1. 像素</a></li>
<li><a href="#112">1.1.2. 亮度</a></li>
<li><a href="#113">1.1.3. 对比度</a></li>
<li><a href="#114">1.1.4. 饱和度</a></li>
</ul>
</li>
<li><a href="#12">1.2. 视频</a><ul>
<li><a href="#121">1.2.1. 帧数</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#2">2. 数字图像与颜色空间</a><ul>
<li><a href="#21-rgb">2.1. RGB 颜色空间基本概念</a><ul>
<li><a href="#22-rbg">2.2. RBG通道直方图</a></li>
<li><a href="#221">2.2.1. 直方图的均衡化</a></li>
</ul>
</li>
<li><a href="#hsv">HSV颜色模型</a></li>
<li><a href="#23">2.3. 图像解压</a></li>
</ul>
</li>
<li><a href="#3">3. 数据增强</a></li>
<li><a href="#4">4. 模型指标</a><ul>
<li><a href="#41">4.1. 又好（准确性）</a><ul>
<li><a href="#411-iou">4.1.1. IOU</a></li>
<li><a href="#412">4.1.2. 精度</a></li>
<li><a href="#413">4.1.3. 召回</a></li>
<li><a href="#414-pr-">4.1.4. PR：精度-召回率曲线</a></li>
<li><a href="#415-ap">4.1.5. AP 平均精度</a></li>
<li><a href="#416-map">4.1.6. mAP 均值平均精度</a></li>
</ul>
</li>
<li><a href="#42">4.2. 又快（实时性）</a><ul>
<li><a href="#421">4.2.1. 每秒处理帧数</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#5">5. 形态学图像处理</a><ul>
<li><a href="#51">5.1. 结构元</a></li>
<li><a href="#52">5.2. 膨胀</a></li>
<li><a href="#53">5.3. 腐蚀</a></li>
<li><a href="#54">5.4. 开运算</a></li>
<li><a href="#55">5.5. 闭运算</a></li>
<li><a href="#56">5.6. 白色顶帽变换</a></li>
<li><a href="#57">5.7. 黑色顶帽变换</a></li>
</ul>
</li>
<li><a href="#6">6. 边缘检测</a><ul>
<li><a href="#61">6.1. 边缘是什么？</a></li>
<li><a href="#62">6.2. 基本步骤</a></li>
<li><a href="#63">6.3. 高级算法</a><ul>
<li><a href="#631-canny">6.3.1. Canny</a><ul>
<li><a href="#6311">6.3.1.1. 降噪</a></li>
<li><a href="#6312">6.3.1.2. 找出梯度较大的区域</a></li>
<li><a href="#6313">6.3.1.3. 非极大值抑制</a></li>
<li><a href="#6314">6.3.1.4. 双阀值</a></li>
<li><a href="#6315">6.3.1.5. 滞后边缘追踪</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#7">7. 参考资料</a></li>
</ul>
</div>
<h1 id="1">1. 基本概念</h1>
<h2 id="11">1.1. 图像</h2>
<h3 id="111">1.1.1. 像素</h3>
<p><code>像素</code>是指由图像的小方格组成的，这些小方块都有一个明确的位置和被分配的色彩数值，小方格颜色和位置就决定该图像所呈现出来的样子。</p>
<p>我们来读取一张形状为 400×500 （高和宽分别为400像素和500像素）的图像作为实</p>
<h3 id="112">1.1.2. 亮度</h3>
<p>图象亮度：一副图像给人的一种直观感受，如果是灰度图像，则跟灰度值有关，灰度值越高则图像越亮。</p>
<h3 id="113">1.1.3. 对比度</h3>
<p>对比度指的是一幅图像中明暗区域最亮的白和最暗的黑之间不同亮度层级的测量，差异范围越大代表对比越大，差异范围越小代表对比越小.</p>
<p>好的对比率120:1就可容易地显示生动、丰富的色彩，当对比率高达300:1时，便可支持各阶的颜色。</p>
<h3 id="114">1.1.4. 饱和度</h3>
<p>图象饱和度：彩色图像的概念，饱和度为0的话，图像表现为灰度图像；饱和度越高颜色表现出种类越多，颜色表现更丰富，反之亦然。</p>
<h2 id="12">1.2. 视频</h2>
<h3 id="121">1.2.1. 帧数</h3>
<p>FPS （每秒传输帧数(Frames Per Second)）<br />
电影以每秒24张画面的速度播放，也就是一秒钟内在屏幕上连续投射出24张静止画面。有关动画播放速度的单位是fps</p>
<h1 id="2">2. 数字图像与颜色空间</h1>
<p>数字图像指的是现在的图像都是以二维数字表示，每个像素的灰度值均由一个数字表示，范围为0-255(2^8)</p>
<ul>
<li>
<p><code>二值图像</code>(Binary Image)：图像中每个像素的灰度值仅可取0或1，即不是取黑，就是取白，二值图像可理解为黑白图像</p>
</li>
<li>
<p><code>灰度图像(</code>Gray Scale Image)：图像中每个像素可以由0-255的灰度值表示，具体表现为从全黑到全白中间有255个介于中间的灰色值可以取</p>
</li>
<li>
<p><code>彩色图像</code>(Color Image)：每幅图像是由三幅灰度图像组合而成，依次表示红绿蓝三通道的灰度值，即我们熟知的RGB，此时彩色图像要视为三维的[height，width, 3]</p>
</li>
</ul>
<p>下面用一张图来感受一下灰度图与彩色图像之间的联系与差别</p>
<p><img alt="" src="../../attach/images/2020-09-01-16-57-41.png" /></p>
<h2 id="21-rgb">2.1. RGB 颜色空间基本概念</h2>
<p><code>RGB颜色空间</code>基于颜色的加法混色原理，从黑色不断叠加红、绿、蓝的颜色，最终可以得到白色光。</p>
<p>RGB颜色空间的图像具有三种颜色通道：红色，绿色和蓝色（RGB），可在像素中产生颜色。</p>
<h3 id="22-rbg">2.2. RBG通道直方图</h3>
<p>直方图，是一种对数据分布情况的图形表示，也就是一种二维的统计图表（<strong>统计学的概念</strong>）。</p>
<p>在图像领域里，我们选取的坐标一般是统计样本（图像、视频帧）和样本的某种属性（亮度、像素值、梯度、方向、色彩等等任何特征）。</p>
<p>图像的直方图是用来表现图像中亮度分布的直方图，给出的是图像中某个亮度或者某个范围亮度下共有几个像素。</p>
<p><img alt="" src="../../attach/images/2020-08-28-16-26-13.png" /></p>
<p>可以看到，红色通道直方图的凸起主要集中在右边，这说明在很多像素中的  R值都是非常大的，也就意味着红色的发光强度大；而红色通道直方图最左端没有凸起，这意味着没有任何一个像素中的 R 值为0，也就意味着在所有像素中红色都发光了。而绿色通道直方图和蓝色通道直方图的凸起都集中在左边，这也就意味着所有的 G 值和 B 都是较小的，因此绿色和蓝色的发光强度弱，所以最后画面呈现出较强的红色。</p>
<h3 id="221">2.2.1. 直方图的均衡化</h3>
<p>直方图均衡化是通过拉伸像素强度的分布范围，使得在0~255灰阶上的分布更加均衡，提高了图像的对比度，达到改善图像主观视觉效果的目的。对比度较低的图像适合使用直方图均衡化方法来增强图像细节。</p>
<h2 id="hsv">HSV颜色模型</h2>
<p>这个模型中颜色的参数分别是：色调（H），饱和度（S），明度（V）。</p>
<p>RGB和 CMY颜色模型都是面向硬件的，而HSV（Hue Saturation Value）颜色模型是面向用户的。</p>
<h2 id="23">2.3. 图像解压</h2>
<p>OpenCV使用JPEG图像的整数精确解压缩而引起的。相反，TensorFlow使用离散余弦变换作为默认值。这种类型的解码不准确，因此要使其与OpenCV相同，我们需要使用整数精确解压缩对其进行解码。可以通过设置参数dct_method ='INTEGER_ACCURATE'来完成，如下所示</p>
<div class="hlcode"><pre><span class="n">image_tf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="err">（</span><span class="n">image_path</span><span class="err">）</span>
<span class="n">image_tf</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">decode_jpeg</span><span class="err">（</span><span class="n">image_tf</span><span class="err">，</span><span class="n">channel</span> <span class="o">=</span> <span class="mi">3</span><span class="err">，</span><span class="n">dct_method</span> <span class="o">=</span><span class="s">&#39;INTEGER_ACCURATE&#39;</span><span class="err">）</span>
<span class="err">与</span><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="err">（）</span><span class="n">sess</span><span class="err">：</span>
    <span class="n">image_tf</span> <span class="o">=</span> <span class="n">image_tf</span><span class="o">.</span><span class="n">eval</span><span class="err">（）</span>
<span class="n">plt_display</span><span class="err">（</span><span class="n">image_tf</span><span class="err">，</span><span class="s">&#39;TF_INT_ACC&#39;</span><span class="err">）</span>
</pre></div>


<h1 id="3">3. 数据增强</h1>
<p>图像增广（image augmentation）是数据增强在图像上说明，图像增广技术通过对训练图像做一系列随机改变，来产生相似但又不同的训练样本，从而扩大训练数据集的规模。</p>
<p>图像增广的另一种解释是，随机改变训练样本可以降低模型对某些属性的依赖，从而提高模型的泛化能力。</p>
<h1 id="4">4. 模型指标</h1>
<h2 id="41">4.1. 又好（准确性）</h2>
<p><img alt="" src="../../attach/images/2020-08-26-19-22-25.png" /></p>
<h3 id="411-iou">4.1.1. IOU</h3>
<p><img alt="" src="../../attach/images/2020-08-26-19-24-51.png" /></p>
<h3 id="412">4.1.2. 精度</h3>
<p><img alt="" src="../../attach/images/2020-08-26-19-23-00.png" /></p>
<h3 id="413">4.1.3. 召回</h3>
<p><img alt="" src="../../attach/images/2020-08-26-19-23-38.png" /></p>
<h3 id="414-pr-">4.1.4. PR：精度-召回率曲线</h3>
<p>Precision-RecallPrecision−Recall 曲线</p>
<p>这条曲线的两个变量程负相关，精度越高，召回率越低；召回率越高，精度越低。</p>
<p>如果将所有对象都预测为正类，没有被错误预测成负类的正类（FN为0）那么召回率将为100%；如果将所有对象的预测都为负，没有被错误预测成正的样本，那么精度就将为100%,这两个指标间存在着此消彼长的关系，理想的曲线是向右上方凸出的、包围面积大的曲线。</p>
<h3 id="415-ap">4.1.5. AP 平均精度</h3>
<p>AP均匀精度Average Precision：PR曲线下所围成的面积，面积越大越好；这里的average指的是针对不同recall的平均精度。</p>
<h3 id="416-map">4.1.6. mAP 均值平均精度</h3>
<p>均值平均精度（Mean Average Precision, mAP）</p>
<h2 id="42">4.2. 又快（实时性）</h2>
<h3 id="421">4.2.1. 每秒处理帧数</h3>
<p>每秒处理帧数（Frame per seconds,fps）</p>
<h1 id="5">5. 形态学图像处理</h1>
<p>形态学图像处理（简称形态学）是指一系列处理图像形状特征的图像处理技术。</p>
<p>形态学的基本思想是利用一种特殊的结构元来测量或提取输入图像中相应的形状或特征，以便进一步进行图像分析和目标识别。</p>
<p>形态学方法的基础是<code>集合论</code>。</p>
<p>形态学方法由J. Serra 于1964年提出。</p>
<p>形态学最基本的操作是<code>腐蚀</code>和<code>膨胀</code>。</p>
<p>形态学操作的使用需要先定义：<br />
1. 一个结构元(Structuring Elements，SE)<br />
2. 指定结构元的原点</p>
<p>不做特殊说明，输入图像为二值图像。图像中1是前景，0是背景。</p>
<h2 id="51">5.1. 结构元</h2>
<p><code>结构元</code>（Structuring Elements，SE）可以是<code>任意形状</code>、<code>任意大小</code>，SE中的的值可以是0或1。常见的结构元有:<br />
1. 矩形<br />
2. 十字形<br />
3. 椭圆形</p>
<p><code>结构元的原点</code>(锚点)O可以是任意位置，一般定义为结构元的中心。</p>
<p>如下图所示，红色区域是几个不同形状的结构元，紫红色区域为锚点O。</p>
<p><img alt="" src="../../attach/images/2020-09-01-15-41-31.png" /></p>
<h2 id="52">5.2. 膨胀</h2>
<p>膨胀（Dilation），就是将结构元$s$ 在图像 $f$ 上滑动，把结构元锚点位置的图像像素点的灰度值设置为结构元值为1的区域对应图像区域像素的最大值。用公式表示如下:<br />
$$dst(x,y)=\max(src(x+x^{'},y+y^{'}))$$</p>
<p>其中element为结构元，(x,y)为锚点O的位置，x'和y'为结构元值为1的像素相对锚点O的位置偏移，src表示原图，dst表示结果图。</p>
<p><img alt="" src="../../attach/images/2020-09-01-15-42-41.png" /></p>
<h2 id="53">5.3. 腐蚀</h2>
<p>$$dst(x,y)=\min(src(x+x^{'},y+y^{'})) $$<br />
<img alt="" src="../../attach/images/2020-09-01-15-43-00.png" /></p>
<p>相比腐蚀和膨胀，基于他们的组合操作在图像处理中的应用更为广泛，常见的组合方式有：<br />
1. 开运算<br />
2. 闭运算。</p>
<p>开操作对图片先腐蚀再膨胀，可以将图片中细小的连接结构断开；<br />
闭操作对图片先膨胀再腐蚀，可以将断裂的物体重新连成一个整体。 </p>
<p>通过基本形态学操作的组合和多种集合关系的应用，可以实现：<strong>边界提取</strong>、<strong>孔洞填充</strong>、<strong>连通分量提取</strong>、计算区域的凸壳、细化、粗化、提取骨架和裁剪等复杂功能。<sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<h2 id="54">5.4. 开运算</h2>
<p>开运算（Opening）：先腐蚀再膨胀</p>
<div class="hlcode"><pre><span class="c"># 开运算</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">23</span><span class="p">,</span> <span class="mi">23</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="n">opened</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">morphologyEx</span><span class="p">(</span><span class="n">blurred</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">MORPH_OPEN</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>  
<span class="c"># cv2.imshow(&#39;opened&#39;,opened)</span>
<span class="n">opened</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">addWeighted</span><span class="p">(</span><span class="n">blurred</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">opened</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>


<p>关于图像融合的线性方法即使用addweighted函数进行图像融合，其核心是ROI感兴趣区域的定义，ROI区域在opencv中就是矩形区域(RECT)</p>
<div class="hlcode"><pre><span class="c"># 得到一个5x5的矩形结构元</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getStructuringElement</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">MORPH_RECT</span><span class="p">,(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c"># 执行开闭运算的次数 </span>
<span class="n">open_res</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">morphologyEx</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">MORPH_OPEN</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>
</pre></div>


<p><img alt="" src="../../attach/images/2020-09-01-15-43-26.png" /></p>
<h2 id="55">5.5. 闭运算</h2>
<p>闭运算（Closing）： 先膨胀再腐蚀</p>
<div class="hlcode"><pre><span class="n">kernel</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">getStructuringElement</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">MORPH_RECT</span><span class="p">,(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c"># 执行闭操作的次数 </span>
<span class="n">close_res</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">morphologyEx</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">MORPH_CLOSE</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">iterations</span><span class="p">)</span>
</pre></div>


<p><img alt="" src="../../attach/images/2020-09-01-15-39-54.png" /></p>
<h2 id="56">5.6. 白色顶帽变换</h2>
<p>白色顶帽变换（white top-hat）是原图像与开运算结果图之差，用公式表示为：</p>
<p>$$T_w(f)=f-fs$$<br />
$$T_w(f)=原始图片-开运算图$$<br />
白色顶帽变换变换可以得到图像中那些面积小于结构元且比周围亮的区域，示意图如下：</p>
<p><img alt="" src="../../attach/images/2020-09-01-16-38-15.png" /></p>
<h2 id="57">5.7. 黑色顶帽变换</h2>
<p>黑色顶帽变换（blacktop-hat）是闭运算结果图与原图之差，用公式表示为：</p>
<p>$$T_w(f)=fs-f$$</p>
<p>$$T_w(f)=闭运算图-原始图片$$<br />
黑色顶帽变换可以得到图像中那些面积小于结构元且比周围暗的区域。</p>
<p><img alt="" src="../../attach/images/2020-09-01-16-38-51.png" /></p>
<h1 id="6">6. 边缘检测</h1>
<h2 id="61">6.1. 边缘是什么？</h2>
<p>边缘就是灰度值变化较大的的像素点的集合。一道黑边一道白边中间就是边缘，它的灰度值变化是最大的，在图像中，用梯度来表示灰度值的变化程度和方向。</p>
<p>由于图像中不可避免的存在噪声和模糊，边缘检测往往与滤波操作结合使用。边缘检测可以通过计算图片中像素点的一阶导数或者二阶导数实现。</p>
<p><strong>边缘检测本质上就是一种滤波算法</strong>，区别在于滤波器的选择，滤波的规则是完全一致的。</p>
<h2 id="62">6.2. 基本步骤</h2>
<p>边缘检测的一般步骤：<br />
1. 滤波——消除噪声<br />
2. 增强——使边界轮廓更加明显<br />
3. 检测——选出边缘点</p>
<p>图像的滤波<strong>一般是基于灰度图</strong>进行的。</p>
<p>边缘检测是基于灰度突变实现图像分割最常用的方法，根据灰度剖面分类，边缘模型有:<br />
1. 台阶模型<br />
2. 斜坡模型<br />
3. 屋顶边缘模型</p>
<h2 id="63">6.3. 高级算法</h2>
<h3 id="631-canny">6.3.1. Canny</h3>
<p>Canny边缘检测是一种流行的边缘检测算法。它是由约翰坎尼在1986年开发的。这是一个多阶段的算法。其目标是找到一个最优的边缘，其最优边缘的定义是：<br />
1. 好的检测 --算法能够尽可能多地标示出图像中的实际边缘<br />
2. 好的定位 --标识出的边缘要与实际图像中的实际边缘尽可能接近<br />
3. 最小响应 --图像中的边缘只能标识一次，并且可能存在的图像噪声不应该标识为边缘</p>
<p>步骤：<br />
1. Noise Reduction<br />
2. Finding Intensity Gradient of the Image<br />
3. Non-Maximun Suppression<br />
4. Double Threhold<br />
5. Edge tracking by hysteresis</p>
<h4 id="6311">6.3.1.1. 降噪</h4>
<p>图片中的高频信息指颜色快速变化，低频信息指颜色平缓的变化。边缘检测过程中需要检测的图片边缘属于高频信息。而图片中噪声部分也属于高频信息，因此我们需要对图像进行去噪处理。</p>
<p>常用的是使用5*5的<strong>高斯滤波核</strong>来平滑图像，滤波核的数量呈高斯分布。</p>
<h4 id="6312">6.3.1.2. 找出梯度较大的区域</h4>
<p>计算像素梯度的幅值以及方向，常用的算子有Rober，sobel，计算水平及垂直方向的差分。找出梯度较大的区域，这部分区域属于图像增强的区域，此时得到的边缘信息比较粗大。</p>
<h4 id="6313">6.3.1.3. 非极大值抑制</h4>
<p>非极大值抑制属于一种边缘细化的方法，梯度大的位置有可能为边缘，在这些位置沿着梯度方向，找到像素点的局部最大值，并将非最大值抑制。</p>
<h4 id="6314">6.3.1.4. 双阀值</h4>
<p>由于存在很多伪边缘，因此Canny算法中所采用的算法为双阈值法，具体思路为选取两个阈值，将小于低阈值的点认为是假边缘置0，将大于高阈值的点认为是强边缘置1，介于中间的像素点需进行进一步的检查。</p>
<p>双阀值方法，设置一个maxval，以及一个minval，梯度大于maxval则为强边缘，梯度值介于maxval与minval则为弱边缘点，小于minval为抑制点。</p>
<h4 id="6315">6.3.1.5. 滞后边缘追踪</h4>
<p>滞后边缘追踪，主要处理梯度值位于maxval，minval中的一些像素点。由于边缘是连续的，因此可以认为弱边缘如果为真实边缘则和强边缘是联通的，可由此判断其是否为真实边缘。</p>
<h1 id="7">7. 参考资料</h1>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p><a href="https://zhuanlan.zhihu.com/p/110787009">知乎：图像处理中常见的形态学方法</a>&#160;<a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2020 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>