<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>Tensorflow底层及基本架构 - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/javascript" async src="https://cdn.bootcss.com/mathjax-mhchem/3.3.2/mhchem.js">
    </script>



</head>

<body>
    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Data_Scince\Library_Platform\Tensorflow">Data_Scince\Library_Platform\Tensorflow</a>&nbsp;»&nbsp;Tensorflow底层及基本架构</div>
</div>
<div class="clearfix"></div>
<div id="title">Tensorflow底层及基本架构</div>
  <div id="content">
  <p>参考 ：<br />
https://blog.csdn.net/qq_30262201/article/details/79106198<br />
整个框架以C API为界，分为前端和后端两大部分。</p>
<p>前端：提供编程模型，多语言的接口支持，比如Python Java C++等。通过C API建立前后端的连接，后面详细讲解。<br />
后端：提供运行环境，完成计算图的执行。进一步分为4层</p>
<p>运行时：分为分布式运行时和本地运行时，负责计算图的接收，构造，编排等。<br />
计算层：提供各op算子的内核实现，例如conv2d, relu等<br />
通信层：实现组件间数据通信，基于GRPC和RDMA两种通信方式<br />
设备层：提供多种异构设备的支持，如CPU GPU TPU FPGA等</p>
<p>TensorFlow的一大特点是，图的构造和执行相分离。用户添加完算子，构建好整图后，才开始进行训练和执行，也就是图的执行。大体流程如下</p>
<p>图构建：用户在client中基于TensorFlow的多语言编程接口，添加算子，完成计算图的构造。</p>
<p>图传递：client开启session，通过它建立和master之间的连接。执行session.run()时，将构造好的graph序列化为graphDef后，以protobuf的格式传递给master。</p>
<p>图剪枝：master根据session.run()传递的fetches和feeds列表，反向遍历全图full graph，实施剪枝，得到最小依赖子图</p>
<p>图分裂：master将最小子图分裂为多个Graph Partition，并注册到多个worker上。一个worker对应一个Graph Partition。</p>
<p>图二次分裂：worker根据当前可用硬件资源，如CPU GPU，将Graph Partition按照op算子设备约束规范（例如tf.device(’/cpu:0’)，二次分裂到不同设备上。每个计算设备对应一个Graph Partition。</p>
<p>图运行：对于每一个计算设备，worker依照op在kernel中的实现，完成op的运算。设备间数据通信可以使用send/recv节点，而worker间通信，则使用GRPC或RDMA协议。</p>
<table>
<thead>
<tr>
<th align="left">一级目录文件</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">ACKNOWLEDGMENTS</td>
<td align="left">TensorFlow 版权声明</td>
</tr>
<tr>
<td align="left">ADOPTERS.md</td>
<td align="left">使用 TensorFlow 的人员或组织列表</td>
</tr>
<tr>
<td align="left">AUTHORS</td>
<td align="left">TensorFlow 作者的官方列表</td>
</tr>
<tr>
<td align="left">BUILD</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">CONTRIBUTING.md</td>
<td align="left">TensorFlow 贡献指导</td>
</tr>
<tr>
<td align="left">ISSUE_TEMPLATE.md</td>
<td align="left">提 ISSUE 的模板</td>
</tr>
<tr>
<td align="left">LICENSE</td>
<td align="left">版权许可</td>
</tr>
<tr>
<td align="left">README.md</td>
<td align="left">RELEASE.md</td>
</tr>
<tr>
<td align="left">每次发版的 change log</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">WORKSPACE</td>
<td align="left">配置移动端开发环境</td>
</tr>
<tr>
<td align="left">bower.BUILD</td>
<td align="left"></td>
</tr>
<tr>
<td align="left">configure</td>
<td align="left">models.BUILD</td>
</tr>
<tr>
<td align="left">tensorflow</td>
<td align="left">主目录，后面分析的重点</td>
</tr>
<tr>
<td align="left">third_party</td>
<td align="left">第三方库，包括 eigen3（特征运算的库，包括 SVD、LU 分解等）、gpus（支持 cuda）、 hadoop、jpeg、llvm、py、sycl</td>
</tr>
<tr>
<td align="left">tools</td>
<td align="left">构建 cuda 支持 └── util</td>
</tr>
</tbody>
</table>
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2019 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>
    
</body>

</html>