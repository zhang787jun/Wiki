<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>Spark 安装与部署 - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Distributed_System">Distributed_System</a>&nbsp;»&nbsp;<a href="/Wiki/#-02-分布式计算系统">02-分布式计算系统</a>&nbsp;»&nbsp;<a href="/Wiki/#-02-Spark">02-Spark</a>&nbsp;»&nbsp;<a href="/Wiki/#-2-实践">2-实践</a>&nbsp;»&nbsp;Spark 安装与部署</div>
</div>
<div class="clearfix"></div>
<div id="title">Spark 安装与部署</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#1">1. 本地部署</a><ul>
<li><a href="#11-spark-on-google-colab">1.1. spark on google colab</a></li>
</ul>
</li>
<li><a href="#2-spark-on-yarn">2. Spark On Yarn</a><ul>
<li><a href="#21">2.1. 概念</a><ul>
<li><a href="#2101-mesos">2.1.0.1. Mesos</a></li>
<li><a href="#211-docker">2.1.1. 基于docker</a><ul>
<li><a href="#2111">2.1.1.1. 单击版</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#22-spark">2.2. 搭建spark集群</a><ul>
<li><a href="#22001">2.2.0.0.1. 设置系统路由转发功能</a></li>
<li><a href="#22002">2.2.0.0.2. 创建一个网络</a><ul>
<li><a href="#220021-spark-master">2.2.0.0.2.1. 启动 spark-master</a></li>
<li><a href="#220022-spark-worker">2.2.0.0.2.2. 启动 spark-worker</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#3-spark-on-k8s">3. Spark on k8s</a><ul>
<li><a href="#31-helm-spark-on-k8s">3.1. 通过 Helm 部署 Spark on k8s</a></li>
</ul>
</li>
</ul>
</div>
<h1 id="1">1. 本地部署</h1>
<h2 id="11-spark-on-google-colab">1.1. spark on google colab</h2>
<div class="hlcode"><pre><span class="sx">!apt install openjdk-8-jdk-headless</span>
<span class="sx">!wget -q https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz</span>
<span class="sx">!tar xf spark-2.4.3-bin-hadoop2.7.tgz</span>
<span class="sx">!pip install -q findspark</span>
<span class="n">import</span> <span class="n">os</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span>&quot;<span class="n">JAVA_HOME</span>&quot;<span class="p">]</span> <span class="p">=</span> &quot;<span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">jvm</span><span class="o">/</span><span class="n">java</span><span class="o">-</span><span class="mi">8</span><span class="o">-</span><span class="n">openjdk</span><span class="o">-</span><span class="n">amd64</span>&quot;
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span>&quot;<span class="n">SPARK_HOME</span>&quot;<span class="p">]</span> <span class="p">=</span> &quot;<span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">spark</span><span class="o">-</span><span class="mf">2.4</span><span class="p">.</span><span class="mi">3</span><span class="o">-</span><span class="n">bin</span><span class="o">-</span><span class="n">hadoop2</span><span class="p">.</span><span class="mi">7</span>&quot;
<span class="sx">!update-alternatives --config java</span>
#<span class="n">select</span> <span class="n">openjdk1</span><span class="p">.</span><span class="mi">8</span>  <span class="n">enter</span>

<span class="n">import</span> <span class="n">findspark</span>
<span class="n">findspark</span><span class="p">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">from</span> <span class="n">pyspark</span><span class="p">.</span><span class="n">sql</span> <span class="n">import</span> <span class="n">SparkSession</span>
<span class="n">spark</span> <span class="p">=</span> <span class="n">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">master</span><span class="p">(</span>&quot;<span class="n">local</span><span class="p">[</span><span class="o">*</span><span class="p">]</span>&quot;<span class="p">).</span><span class="n">getOrCreate</span><span class="p">()</span>
</pre></div>


<h1 id="2-spark-on-yarn">2. Spark On Yarn</h1>
<h2 id="21">2.1. 概念</h2>
<p>Spark on Yarn的两种运行模式：cluster和client;<br />
一句话概述两种的区别就是Spark driver到底运行再什么地方<br />
In cluster mode：Driver运行在NodeManage的AM(Application Master)中，它负责向YARN申请资源，并监督作业的运行状况。当用户提交了作业之后，就可以关掉Client，作业会继续在YARN上运行。<br />
In client mode:Driver运行在Client上，通过ApplicationMaster向RM获取资源。本地Driver负责与所有的executor container进行交互</p>
<h4 id="2101-mesos">2.1.0.1. Mesos</h4>
<h3 id="211-docker">2.1.1. 基于docker</h3>
<h4 id="2111">2.1.1.1. 单击版</h4>
<p>参考：https://hub.docker.com/r/sequenceiq/spark/</p>
<div class="hlcode"><pre><span class="n">docker</span> <span class="n">pull</span> <span class="n">sequenceiq</span><span class="o">/</span><span class="n">spark</span><span class="o">:</span><span class="mf">1.6.0</span>
</pre></div>


<h2 id="22-spark">2.2. 搭建spark集群</h2>
<h5 id="22001">2.2.0.0.1. 设置系统路由转发功能</h5>
<div class="hlcode"><pre><span class="err">修改配置文件</span> 
<span class="n">vim</span> <span class="o">/</span><span class="n">etc</span><span class="o">/</span><span class="n">sysctl</span><span class="p">.</span><span class="n">conf</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="cp">#新增一条：</span>
<span class="n">net</span><span class="p">.</span><span class="n">ipv4</span><span class="p">.</span><span class="n">ip_forward</span><span class="o">=</span><span class="mi">1</span> 
<span class="cp"># 0 时表示禁止进行IP转发</span>
<span class="cp"># 1 IP转发功能已经打开</span>

<span class="cp">#重启网络：</span>
<span class="n">systemctl</span> <span class="n">restart</span> <span class="n">network</span>
<span class="cp">#验证配置：</span>
<span class="n">sysctl</span> <span class="n">net</span><span class="p">.</span><span class="n">ipv4</span><span class="p">.</span><span class="n">ip_forward</span>
</pre></div>


<h5 id="22002">2.2.0.0.2. 创建一个网络</h5>
<p>为本地群集创建一个网络<br />
创建网络非常简单，可以通过运行以下命令来完成：<br />
桥接网络类似于默认bridge网络</p>
<div class="hlcode"><pre><span class="n">docker</span> <span class="n">network</span> <span class="n">create</span> <span class="n">spark_network</span>
</pre></div>


<h6 id="220021-spark-master">2.2.0.0.2.1. 启动 spark-master</h6>
<div class="hlcode"><pre><span class="n">docker</span> <span class="n">run</span> <span class="o">--</span><span class="n">rm</span> <span class="o">-</span><span class="n">it</span> <span class="o">--</span><span class="n">name</span> <span class="n">spark</span><span class="o">-</span><span class="n">master</span> <span class="o">--</span><span class="n">hostname</span> <span class="n">spark</span><span class="o">-</span><span class="n">master</span> \
    <span class="o">-</span><span class="n">p</span> <span class="mi">7077</span><span class="o">:</span><span class="mi">7077</span> <span class="o">-</span><span class="n">p</span> <span class="mi">8080</span><span class="o">:</span><span class="mi">8080</span> <span class="o">--</span><span class="n">network</span> <span class="n">spark_network</span> \
    <span class="o">&lt;</span><span class="n">spark</span><span class="o">-</span><span class="n">image</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span> <span class="o">/</span><span class="n">bin</span><span class="o">/</span><span class="n">sh</span>
</pre></div>


<h6 id="220022-spark-worker">2.2.0.0.2.2. 启动 spark-worker</h6>
<div class="hlcode"><pre><span class="n">docker</span> <span class="n">run</span> <span class="o">--</span><span class="n">rm</span> <span class="o">-</span><span class="n">it</span> <span class="o">--</span><span class="n">name</span> <span class="n">spark</span><span class="o">-</span><span class="n">worker1</span> <span class="o">--</span><span class="n">hostname</span> <span class="n">spark</span><span class="o">-</span><span class="n">worker1</span> \
    <span class="o">--</span><span class="n">network</span> <span class="n">spark_network</span> \
    <span class="o">&lt;</span><span class="n">spark</span><span class="o">-</span><span class="n">image</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span> <span class="o">/</span><span class="n">bin</span><span class="o">/</span><span class="n">sh</span>
<span class="cp"># 输入</span>
<span class="o">/</span><span class="n">spark</span><span class="o">/</span><span class="n">bin</span><span class="o">/</span><span class="n">spark</span><span class="o">-</span><span class="n">class</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">spark</span><span class="p">.</span><span class="n">deploy</span><span class="p">.</span><span class="n">worker</span><span class="p">.</span><span class="n">Worker</span> \
    <span class="o">--</span><span class="n">webui</span><span class="o">-</span><span class="n">port</span> <span class="mi">8080</span> <span class="n">spark</span><span class="o">:</span><span class="c1">//spark-master:7077</span>
</pre></div>


<h1 id="3-spark-on-k8s">3. Spark on k8s</h1>
<h2 id="31-helm-spark-on-k8s">3.1. 通过 Helm 部署 Spark on k8s</h2>
<p>下面我们将利用 Helm，来部署 Spark 以用于大数据处理。</p>
<p>输入如下命令。</p>
<div class="hlcode"><pre><span class="n">helm</span> <span class="n">install</span> <span class="n">stable</span><span class="o">/</span><span class="n">spark</span> <span class="o">--</span><span class="n">namespace</span> <span class="n">spark</span><span class="o">-</span><span class="n">on</span><span class="o">-</span><span class="n">k8s</span> <span class="o">--</span><span class="n">generate</span><span class="o">-</span><span class="n">name</span>

<span class="cp"># 得到如下的结果。</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="nl">NAME:</span>   <span class="n">myspark</span>
<span class="n">LAST</span> <span class="n">DEPLOYED</span><span class="o">:</span> <span class="n">Mon</span> <span class="n">Nov</span> <span class="mi">20</span> <span class="mi">19</span><span class="o">:</span><span class="mi">24</span><span class="o">:</span><span class="mi">22</span> <span class="mi">2017</span>
<span class="nl">NAMESPACE:</span> <span class="k">default</span>
<span class="nl">STATUS:</span> <span class="n">DEPLOYED</span>
<span class="p">...</span>
</pre></div>


<p>利用如下命令查看 Spark 的 release 和 service。</p>
<div class="hlcode"><pre><span class="n">helm</span> <span class="n">list</span>
<span class="n">kubectl</span> <span class="n">get</span> <span class="n">svc</span>
</pre></div>


<p>利用如下命令查看 Spark 相关的 Pod，并等待其状态变为 Running。因为 Spark 的相关镜像体积较大，所以拉取镜像需要一定的时间。</p>
<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span>
</pre></div>


<p>利用如下命令获得 Spark Web UI 的访问地址。</p>
<div class="hlcode"><pre><span class="n">echo</span> <span class="n">http</span><span class="o">:</span><span class="c1">//$(kubectl get svc myspark-webui -o jsonpath=&#39;{.status.loadBalancer.ingress[0].ip}&#39;):8080</span>
</pre></div>


<p>通过上面的 URL，可以在浏览器上看到 Spark 的 Web UI，上面显示 worker 实例当前为 3 个。</p>
<p>接下来，我们将利用如下命令，使用 Helm 对 Spark 应用做升级，将 worker 实例数量从 3 个变更为 4 个。请注意参数名称是大小写敏感的。</p>
<div class="hlcode"><pre><span class="n">helm</span> <span class="n">upgrade</span> <span class="n">myspark</span> <span class="o">--</span><span class="n">set</span> <span class="s">&quot;Worker.Replicas=4&quot;</span> <span class="n">stable</span><span class="o">/</span><span class="n">spark</span>
<span class="err">得到如下结果。</span>

<span class="n">Release</span> <span class="s">&quot;myspark&quot;</span> <span class="n">has</span> <span class="n">been</span> <span class="n">upgraded</span><span class="p">.</span> <span class="n">Happy</span> <span class="n">Helming</span><span class="o">!</span>
<span class="n">LAST</span> <span class="n">DEPLOYED</span><span class="o">:</span> <span class="n">Mon</span> <span class="n">Nov</span> <span class="mi">20</span> <span class="mi">19</span><span class="o">:</span><span class="mi">27</span><span class="o">:</span><span class="mi">29</span> <span class="mi">2017</span>
<span class="nl">NAMESPACE:</span> <span class="k">default</span>
<span class="nl">STATUS:</span> <span class="n">DEPLOYED</span>
</pre></div>


<p>...<br />
利用如下命令查看 Spark 新增的 Pod，并等待其状态变为 Running。</p>
<div class="hlcode"><pre><span class="n">kubectl</span> <span class="n">get</span> <span class="n">pod</span>
</pre></div>


<p>在浏览器上刷新 Spark 的 Web UI，可以看到此时 worker 数量已经变为 4 个。</p>
<p>如需彻底删除 Spark 应用，可输入如下命令。</p>
<div class="hlcode"><pre><span class="n">helm</span> <span class="n">delete</span> <span class="o">--</span><span class="n">purge</span> <span class="n">myspark</span>
</pre></div>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2021 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>